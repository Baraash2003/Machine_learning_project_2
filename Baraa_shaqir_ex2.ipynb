{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Q3S5loqBCqgM",
      "metadata": {
        "id": "Q3S5loqBCqgM"
      },
      "source": [
        "Libraries (don't change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5f1ba5ec",
      "metadata": {
        "id": "5f1ba5ec"
      },
      "outputs": [],
      "source": [
        "# Github Link:\n",
        "#Ameer Espanioly - 213471618: https://github.com/Ameer618/Machine_Learning_Ex2\n",
        "#Baraa Shaqir - 213971294 - https://github.com/Baraash2003/Machine_learning_project_2\n",
        "#Deema Shaqir - 314947623 - https://github.com/deemashaqir/Machine_learning_project2\n",
        "\n",
        "!pip -q install torchinfo\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Callable, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torchinfo import summary\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ykrfYnc6g1Bs",
      "metadata": {
        "id": "ykrfYnc6g1Bs"
      },
      "source": [
        "Device (don't change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "XJIYaWIggSCp",
      "metadata": {
        "id": "XJIYaWIggSCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9d6fe6-054b-4d7e-e678-1011e9cb88a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Mixed precision (AMP): True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "use_amp = (DEVICE == \"cuda\")\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Mixed precision (AMP): {use_amp}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d71ffe61",
      "metadata": {
        "id": "d71ffe61"
      },
      "source": [
        "Data (don't change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2cb0bf0c",
      "metadata": {
        "id": "2cb0bf0c"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DataManager:\n",
        "    def __init__(self, dataset_class, root: str = \"./data\", val_fraction: float = 0.1,\n",
        "                 batch_size: int = 32, seed: int = 42):\n",
        "        self.dataset_class = dataset_class\n",
        "        self.root = root\n",
        "        self.val_fraction = val_fraction\n",
        "        self.batch_size = batch_size\n",
        "        self.seed = seed\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1918,), (0.3483,))\n",
        "        ])\n",
        "\n",
        "    def get_loaders(self) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "        full_train = self.dataset_class(root=self.root, train=True,\n",
        "                                        download=True, transform=self.transform)\n",
        "        test_ds = self.dataset_class(root=self.root, train=False,\n",
        "                                     download=True, transform=self.transform)\n",
        "\n",
        "        val_size = int(len(full_train) * self.val_fraction)\n",
        "        train_size = len(full_train) - val_size\n",
        "\n",
        "        generator = torch.Generator().manual_seed(self.seed)\n",
        "        train_ds, val_ds = random_split(full_train, [train_size, val_size], generator=generator)\n",
        "\n",
        "        train_loader = DataLoader(train_ds, batch_size=self.batch_size,\n",
        "                                  shuffle=True, num_workers=2, pin_memory=True)\n",
        "        val_loader   = DataLoader(val_ds,   batch_size=self.batch_size,\n",
        "                                  shuffle=False, num_workers=2, pin_memory=True)\n",
        "        test_loader  = DataLoader(test_ds,  batch_size=self.batch_size,\n",
        "                                  shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "        print(f\"Train: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(test_ds)}\")\n",
        "        return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O0SlvxE36HG0",
      "metadata": {
        "id": "O0SlvxE36HG0"
      },
      "source": [
        "Configurations (don't change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "FwDGf9J66bXL",
      "metadata": {
        "id": "FwDGf9J66bXL"
      },
      "outputs": [],
      "source": [
        "\n",
        "@dataclass\n",
        "class LayerSpec:\n",
        "    out_dim: int\n",
        "    activation: Callable[[torch.Tensor], torch.Tensor] = F.relu\n",
        "    dropout: float = 0.0\n",
        "    batch_norm: bool = True\n",
        "    weight_decay: float = 0.0\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    input_dim: Tuple[int, int, int] = (1, 28, 28)\n",
        "    num_classes: int = 10\n",
        "    layers: List[LayerSpec] = None\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 100\n",
        "    lr: float = 1e-4\n",
        "    patience: int = 15\n",
        "    min_delta: float = 1e-4\n",
        "    val_fraction: float = 0.1\n",
        "    seed: int = 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53221445",
      "metadata": {
        "id": "53221445"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b5843387",
      "metadata": {
        "id": "b5843387"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MLPFromConfig(nn.Module):\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        flat_dim = config.input_dim[0] * config.input_dim[1] * config.input_dim[2]\n",
        "        self.layers_specs = config.layers\n",
        "        layers = []\n",
        "        prev_dim = flat_dim\n",
        "\n",
        "        for i, spec in enumerate(config.layers):\n",
        "            linear = nn.Linear(prev_dim, spec.out_dim)\n",
        "\n",
        "            layers.append(linear)\n",
        "            if spec.batch_norm:\n",
        "                layers.append(nn.BatchNorm1d(spec.out_dim))\n",
        "            if spec.dropout > 0:\n",
        "                layers.append(nn.Dropout(spec.dropout))\n",
        "            layers.append(spec.activation())\n",
        "            prev_dim = spec.out_dim\n",
        "\n",
        "        # Final classifier layer\n",
        "        self.final_linear = nn.Linear(prev_dim, config.num_classes)\n",
        "        layers.append(self.final_linear)\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.net(x)\n",
        "\n",
        "    def get_layer_params(self):\n",
        "        param_groups = []\n",
        "        for i, spec in enumerate(self.layers_specs):\n",
        "            linear_layer = self.net[i * (4 if spec.batch_norm or spec.dropout > 0 else 3)]\n",
        "            pass\n",
        "        return self.layers_specs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eND74vML5XYh",
      "metadata": {
        "id": "eND74vML5XYh"
      },
      "source": [
        "Early Stopping (don't change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "KgImYRwI5hAr",
      "metadata": {
        "id": "KgImYRwI5hAr"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience: int = 10, min_delta: float = 1e-4):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.should_stop = False\n",
        "\n",
        "    def __call__(self, val_loss: float) -> bool:\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.should_stop = True\n",
        "        return self.should_stop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b11a04f",
      "metadata": {
        "id": "9b11a04f"
      },
      "source": [
        "Trainer (don't change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e474713f",
      "metadata": {
        "id": "e474713f"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model: nn.Module, config: TrainConfig):\n",
        "        self.model = model.to(DEVICE)\n",
        "        self.config = config\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = self._build_optimizer()\n",
        "        self.scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "        self.early_stopping = EarlyStopping(patience=config.patience,\n",
        "                                            min_delta=config.min_delta)\n",
        "\n",
        "        self.history = {\"train_loss\": [], \"train_acc\": [],\n",
        "                        \"val_loss\": [], \"val_acc\": []}\n",
        "\n",
        "    def _build_optimizer(self):\n",
        "\n",
        "        # Collect all Linear layers in the order they appear\n",
        "        linear_layers = []\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                linear_layers.append((name, module))\n",
        "\n",
        "        param_groups = []\n",
        "\n",
        "        for i, spec in enumerate(self.model.layers_specs):\n",
        "            name, layer = linear_layers[i]\n",
        "            param_groups.append({\n",
        "                'params': layer.parameters(),\n",
        "                'weight_decay': spec.weight_decay\n",
        "            })\n",
        "\n",
        "        final_name, final_layer = linear_layers[-1]\n",
        "        param_groups.append({\n",
        "            'params': final_layer.parameters(),\n",
        "            'weight_decay': 0.0\n",
        "        })\n",
        "\n",
        "        return torch.optim.SGD(param_groups, momentum=0.9, nesterov=True, lr=self.config.lr)\n",
        "\n",
        "    def _train_epoch(self, loader: DataLoader):\n",
        "        self.model.train()\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "\n",
        "            self.scaler.scale(loss).backward()\n",
        "            self.scaler.step(self.optimizer)\n",
        "            self.scaler.update()\n",
        "\n",
        "            total_loss += loss.item() * data.size(0)\n",
        "            correct += (output.argmax(1) == target).sum().item()\n",
        "            total += data.size(0)\n",
        "\n",
        "        return total_loss / total, correct / total\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _eval_epoch(self, loader: DataLoader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "\n",
        "            total_loss += loss.item() * data.size(0)\n",
        "            correct += (output.argmax(1) == target).sum().item()\n",
        "            total += data.size(0)\n",
        "\n",
        "        return total_loss / total, correct / total\n",
        "\n",
        "    def fit(self, train_loader: DataLoader, val_loader: DataLoader):\n",
        "        print(\"ðŸš€ Starting training...\\n\")\n",
        "        for epoch in range(1, self.config.epochs + 1):\n",
        "            train_loss, train_acc = self._train_epoch(train_loader)\n",
        "            val_loss, val_acc     = self._eval_epoch(val_loader)\n",
        "\n",
        "            self.history[\"train_loss\"].append(train_loss)\n",
        "            self.history[\"train_acc\"].append(train_acc)\n",
        "            self.history[\"val_loss\"].append(val_loss)\n",
        "            self.history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "            print(f\"Epoch {epoch:3d} | \"\n",
        "                  f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
        "                  f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "            if self.early_stopping(val_loss):\n",
        "                print(f\"\\nðŸ›‘ Early stopping triggered at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "        print(\"\\nâœ… Training complete!\")\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate(self, loader: DataLoader):\n",
        "        return self._eval_epoch(loader)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict_all(self, loader: DataLoader):\n",
        "        self.model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        for x, y in loader:\n",
        "            x = x.to(DEVICE, non_blocking=True)\n",
        "            logits = self.model(x)\n",
        "            preds = logits.argmax(dim=1).cpu().numpy()\n",
        "            all_preds.append(preds)\n",
        "            all_targets.append(y.numpy())\n",
        "        return np.concatenate(all_preds), np.concatenate(all_targets)\n",
        "\n",
        "\n",
        "    def save(self, path: str = \"mlp_best.pt\"):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "        print(f\"ðŸ’¾ Model saved to {path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55c7d02d",
      "metadata": {
        "id": "55c7d02d"
      },
      "source": [
        "\n",
        "Run (do change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d133bb1a",
      "metadata": {
        "id": "d133bb1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "013ca08b-bd66-4b74-8cb0-af0cc0a0446b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.2/779.2 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026/01/11 12:20:53 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2026/01/11 12:20:53 INFO mlflow.store.db.utils: Updating database tables\n",
            "2026/01/11 12:20:53 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2026/01/11 12:20:53 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
            "2026/01/11 12:20:54 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2026/01/11 12:20:55 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2026/01/11 12:20:55 INFO mlflow.tracking.fluent: Experiment with name 'ex2-kmnist-mlp' does not exist. Creating a new experiment.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18.2M/18.2M [00:11<00:00, 1.64MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.5k/29.5k [00:00<00:00, 336kB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.04M/3.04M [00:01<00:00, 1.54MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.12k/5.12k [00:00<00:00, 10.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 54000 | Val: 6000 | Test: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2705984033.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Starting training...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2705984033.py:49: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "/tmp/ipython-input-2705984033.py:72: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   1 | Train Loss: 1.3258 Acc: 0.6170 | Val Loss: 0.8161 Acc: 0.7618\n",
            "Epoch   2 | Train Loss: 0.7084 Acc: 0.7906 | Val Loss: 0.5787 Acc: 0.8292\n",
            "Epoch   3 | Train Loss: 0.5508 Acc: 0.8364 | Val Loss: 0.4774 Acc: 0.8552\n",
            "Epoch   4 | Train Loss: 0.4672 Acc: 0.8614 | Val Loss: 0.4171 Acc: 0.8762\n",
            "Epoch   5 | Train Loss: 0.4105 Acc: 0.8778 | Val Loss: 0.3752 Acc: 0.8897\n",
            "Epoch   6 | Train Loss: 0.3699 Acc: 0.8908 | Val Loss: 0.3410 Acc: 0.8990\n",
            "Epoch   7 | Train Loss: 0.3392 Acc: 0.9004 | Val Loss: 0.3153 Acc: 0.9077\n",
            "Epoch   8 | Train Loss: 0.3113 Acc: 0.9097 | Val Loss: 0.2948 Acc: 0.9150\n",
            "Epoch   9 | Train Loss: 0.2902 Acc: 0.9146 | Val Loss: 0.2804 Acc: 0.9190\n",
            "Epoch  10 | Train Loss: 0.2704 Acc: 0.9208 | Val Loss: 0.2645 Acc: 0.9237\n",
            "Epoch  11 | Train Loss: 0.2518 Acc: 0.9270 | Val Loss: 0.2534 Acc: 0.9287\n",
            "Epoch  12 | Train Loss: 0.2412 Acc: 0.9292 | Val Loss: 0.2425 Acc: 0.9313\n",
            "Epoch  13 | Train Loss: 0.2294 Acc: 0.9320 | Val Loss: 0.2341 Acc: 0.9333\n",
            "Epoch  14 | Train Loss: 0.2155 Acc: 0.9371 | Val Loss: 0.2273 Acc: 0.9363\n",
            "Epoch  15 | Train Loss: 0.2070 Acc: 0.9393 | Val Loss: 0.2211 Acc: 0.9387\n",
            "Epoch  16 | Train Loss: 0.1962 Acc: 0.9412 | Val Loss: 0.2155 Acc: 0.9382\n",
            "Epoch  17 | Train Loss: 0.1882 Acc: 0.9460 | Val Loss: 0.2099 Acc: 0.9393\n",
            "Epoch  18 | Train Loss: 0.1814 Acc: 0.9452 | Val Loss: 0.2057 Acc: 0.9418\n",
            "Epoch  19 | Train Loss: 0.1751 Acc: 0.9488 | Val Loss: 0.2024 Acc: 0.9428\n",
            "Epoch  20 | Train Loss: 0.1680 Acc: 0.9505 | Val Loss: 0.1975 Acc: 0.9445\n",
            "Epoch  21 | Train Loss: 0.1634 Acc: 0.9519 | Val Loss: 0.1947 Acc: 0.9455\n",
            "Epoch  22 | Train Loss: 0.1552 Acc: 0.9544 | Val Loss: 0.1917 Acc: 0.9452\n",
            "Epoch  23 | Train Loss: 0.1485 Acc: 0.9561 | Val Loss: 0.1901 Acc: 0.9450\n",
            "Epoch  24 | Train Loss: 0.1467 Acc: 0.9557 | Val Loss: 0.1863 Acc: 0.9465\n",
            "Epoch  25 | Train Loss: 0.1401 Acc: 0.9587 | Val Loss: 0.1849 Acc: 0.9460\n",
            "Epoch  26 | Train Loss: 0.1357 Acc: 0.9594 | Val Loss: 0.1850 Acc: 0.9458\n",
            "Epoch  27 | Train Loss: 0.1322 Acc: 0.9605 | Val Loss: 0.1826 Acc: 0.9460\n",
            "Epoch  28 | Train Loss: 0.1272 Acc: 0.9616 | Val Loss: 0.1825 Acc: 0.9450\n",
            "Epoch  29 | Train Loss: 0.1222 Acc: 0.9641 | Val Loss: 0.1800 Acc: 0.9463\n",
            "Epoch  30 | Train Loss: 0.1221 Acc: 0.9630 | Val Loss: 0.1772 Acc: 0.9472\n",
            "Epoch  31 | Train Loss: 0.1158 Acc: 0.9658 | Val Loss: 0.1739 Acc: 0.9497\n",
            "Epoch  32 | Train Loss: 0.1152 Acc: 0.9657 | Val Loss: 0.1746 Acc: 0.9488\n",
            "Epoch  33 | Train Loss: 0.1118 Acc: 0.9668 | Val Loss: 0.1764 Acc: 0.9488\n",
            "Epoch  34 | Train Loss: 0.1080 Acc: 0.9675 | Val Loss: 0.1712 Acc: 0.9498\n",
            "Epoch  35 | Train Loss: 0.1048 Acc: 0.9687 | Val Loss: 0.1741 Acc: 0.9502\n",
            "Epoch  36 | Train Loss: 0.1038 Acc: 0.9686 | Val Loss: 0.1724 Acc: 0.9493\n",
            "Epoch  37 | Train Loss: 0.1002 Acc: 0.9698 | Val Loss: 0.1717 Acc: 0.9505\n",
            "Epoch  38 | Train Loss: 0.0975 Acc: 0.9699 | Val Loss: 0.1716 Acc: 0.9505\n",
            "Epoch  39 | Train Loss: 0.0947 Acc: 0.9717 | Val Loss: 0.1695 Acc: 0.9502\n",
            "Epoch  40 | Train Loss: 0.0948 Acc: 0.9716 | Val Loss: 0.1665 Acc: 0.9518\n",
            "\n",
            "âœ… Training complete!\n",
            "ðŸ’¾ Model saved to exp01_baseline_model.pt\n",
            "Train: 54000 | Val: 6000 | Test: 10000\n",
            "ðŸš€ Starting training...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2705984033.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   1 | Train Loss: 1.2195 Acc: 0.6505 | Val Loss: 0.7149 Acc: 0.7923\n",
            "Epoch   2 | Train Loss: 0.6254 Acc: 0.8155 | Val Loss: 0.5169 Acc: 0.8478\n",
            "Epoch   3 | Train Loss: 0.4927 Acc: 0.8546 | Val Loss: 0.4336 Acc: 0.8727\n",
            "Epoch   4 | Train Loss: 0.4209 Acc: 0.8752 | Val Loss: 0.3799 Acc: 0.8888\n",
            "Epoch   5 | Train Loss: 0.3694 Acc: 0.8894 | Val Loss: 0.3407 Acc: 0.8983\n",
            "Epoch   6 | Train Loss: 0.3307 Acc: 0.9018 | Val Loss: 0.3116 Acc: 0.9085\n",
            "Epoch   7 | Train Loss: 0.3014 Acc: 0.9100 | Val Loss: 0.2888 Acc: 0.9155\n",
            "Epoch   8 | Train Loss: 0.2775 Acc: 0.9175 | Val Loss: 0.2706 Acc: 0.9208\n",
            "Epoch   9 | Train Loss: 0.2553 Acc: 0.9246 | Val Loss: 0.2556 Acc: 0.9247\n",
            "Epoch  10 | Train Loss: 0.2388 Acc: 0.9298 | Val Loss: 0.2419 Acc: 0.9285\n",
            "Epoch  11 | Train Loss: 0.2234 Acc: 0.9349 | Val Loss: 0.2335 Acc: 0.9308\n",
            "Epoch  12 | Train Loss: 0.2101 Acc: 0.9384 | Val Loss: 0.2207 Acc: 0.9347\n",
            "Epoch  13 | Train Loss: 0.1993 Acc: 0.9419 | Val Loss: 0.2148 Acc: 0.9362\n",
            "Epoch  14 | Train Loss: 0.1878 Acc: 0.9444 | Val Loss: 0.2071 Acc: 0.9407\n",
            "Epoch  15 | Train Loss: 0.1776 Acc: 0.9475 | Val Loss: 0.2003 Acc: 0.9415\n",
            "Epoch  16 | Train Loss: 0.1725 Acc: 0.9500 | Val Loss: 0.1957 Acc: 0.9443\n",
            "Epoch  17 | Train Loss: 0.1636 Acc: 0.9514 | Val Loss: 0.1911 Acc: 0.9420\n",
            "Epoch  18 | Train Loss: 0.1553 Acc: 0.9551 | Val Loss: 0.1861 Acc: 0.9450\n",
            "Epoch  19 | Train Loss: 0.1475 Acc: 0.9568 | Val Loss: 0.1826 Acc: 0.9453\n",
            "Epoch  20 | Train Loss: 0.1395 Acc: 0.9592 | Val Loss: 0.1777 Acc: 0.9473\n",
            "Epoch  21 | Train Loss: 0.1341 Acc: 0.9607 | Val Loss: 0.1754 Acc: 0.9472\n",
            "Epoch  22 | Train Loss: 0.1266 Acc: 0.9630 | Val Loss: 0.1724 Acc: 0.9480\n",
            "Epoch  23 | Train Loss: 0.1230 Acc: 0.9640 | Val Loss: 0.1698 Acc: 0.9482\n",
            "Epoch  24 | Train Loss: 0.1187 Acc: 0.9654 | Val Loss: 0.1684 Acc: 0.9492\n",
            "Epoch  25 | Train Loss: 0.1163 Acc: 0.9659 | Val Loss: 0.1686 Acc: 0.9497\n",
            "Epoch  26 | Train Loss: 0.1100 Acc: 0.9670 | Val Loss: 0.1655 Acc: 0.9502\n",
            "Epoch  27 | Train Loss: 0.1035 Acc: 0.9693 | Val Loss: 0.1626 Acc: 0.9507\n",
            "Epoch  28 | Train Loss: 0.1024 Acc: 0.9702 | Val Loss: 0.1609 Acc: 0.9522\n",
            "Epoch  29 | Train Loss: 0.0997 Acc: 0.9700 | Val Loss: 0.1606 Acc: 0.9532\n",
            "Epoch  30 | Train Loss: 0.0935 Acc: 0.9727 | Val Loss: 0.1583 Acc: 0.9528\n",
            "Epoch  31 | Train Loss: 0.0901 Acc: 0.9732 | Val Loss: 0.1590 Acc: 0.9522\n",
            "Epoch  32 | Train Loss: 0.0906 Acc: 0.9739 | Val Loss: 0.1588 Acc: 0.9533\n",
            "Epoch  33 | Train Loss: 0.0845 Acc: 0.9754 | Val Loss: 0.1571 Acc: 0.9525\n",
            "Epoch  34 | Train Loss: 0.0813 Acc: 0.9768 | Val Loss: 0.1576 Acc: 0.9532\n",
            "Epoch  35 | Train Loss: 0.0814 Acc: 0.9754 | Val Loss: 0.1579 Acc: 0.9547\n",
            "Epoch  36 | Train Loss: 0.0769 Acc: 0.9782 | Val Loss: 0.1549 Acc: 0.9547\n",
            "Epoch  37 | Train Loss: 0.0720 Acc: 0.9797 | Val Loss: 0.1576 Acc: 0.9542\n",
            "Epoch  38 | Train Loss: 0.0727 Acc: 0.9779 | Val Loss: 0.1559 Acc: 0.9535\n",
            "Epoch  39 | Train Loss: 0.0706 Acc: 0.9795 | Val Loss: 0.1555 Acc: 0.9545\n",
            "Epoch  40 | Train Loss: 0.0684 Acc: 0.9795 | Val Loss: 0.1559 Acc: 0.9548\n",
            "\n",
            "âœ… Training complete!\n",
            "ðŸ’¾ Model saved to exp02_wider_model.pt\n",
            "Train: 54000 | Val: 6000 | Test: 10000\n",
            "ðŸš€ Starting training...\n",
            "\n",
            "Epoch   1 | Train Loss: 1.3763 Acc: 0.5929 | Val Loss: 0.7782 Acc: 0.7763\n",
            "Epoch   2 | Train Loss: 0.6943 Acc: 0.7942 | Val Loss: 0.5069 Acc: 0.8505\n",
            "Epoch   3 | Train Loss: 0.5210 Acc: 0.8434 | Val Loss: 0.3998 Acc: 0.8825\n",
            "Epoch   4 | Train Loss: 0.4378 Acc: 0.8668 | Val Loss: 0.3419 Acc: 0.8992\n",
            "Epoch   5 | Train Loss: 0.3862 Acc: 0.8827 | Val Loss: 0.3010 Acc: 0.9112\n",
            "Epoch   6 | Train Loss: 0.3464 Acc: 0.8937 | Val Loss: 0.2725 Acc: 0.9180\n",
            "Epoch   7 | Train Loss: 0.3134 Acc: 0.9029 | Val Loss: 0.2534 Acc: 0.9235\n",
            "Epoch   8 | Train Loss: 0.2890 Acc: 0.9112 | Val Loss: 0.2358 Acc: 0.9258\n",
            "Epoch   9 | Train Loss: 0.2717 Acc: 0.9166 | Val Loss: 0.2191 Acc: 0.9335\n",
            "Epoch  10 | Train Loss: 0.2529 Acc: 0.9227 | Val Loss: 0.2075 Acc: 0.9367\n",
            "Epoch  11 | Train Loss: 0.2409 Acc: 0.9263 | Val Loss: 0.1997 Acc: 0.9392\n",
            "Epoch  12 | Train Loss: 0.2249 Acc: 0.9302 | Val Loss: 0.1908 Acc: 0.9427\n",
            "Epoch  13 | Train Loss: 0.2160 Acc: 0.9331 | Val Loss: 0.1851 Acc: 0.9442\n",
            "Epoch  14 | Train Loss: 0.2049 Acc: 0.9365 | Val Loss: 0.1821 Acc: 0.9443\n",
            "Epoch  15 | Train Loss: 0.1942 Acc: 0.9399 | Val Loss: 0.1726 Acc: 0.9470\n",
            "Epoch  16 | Train Loss: 0.1865 Acc: 0.9423 | Val Loss: 0.1680 Acc: 0.9487\n",
            "Epoch  17 | Train Loss: 0.1821 Acc: 0.9412 | Val Loss: 0.1662 Acc: 0.9490\n",
            "Epoch  18 | Train Loss: 0.1717 Acc: 0.9462 | Val Loss: 0.1624 Acc: 0.9495\n",
            "Epoch  19 | Train Loss: 0.1664 Acc: 0.9478 | Val Loss: 0.1601 Acc: 0.9517\n",
            "Epoch  20 | Train Loss: 0.1616 Acc: 0.9485 | Val Loss: 0.1581 Acc: 0.9523\n",
            "Epoch  21 | Train Loss: 0.1534 Acc: 0.9516 | Val Loss: 0.1573 Acc: 0.9507\n",
            "Epoch  22 | Train Loss: 0.1489 Acc: 0.9529 | Val Loss: 0.1554 Acc: 0.9515\n",
            "Epoch  23 | Train Loss: 0.1436 Acc: 0.9546 | Val Loss: 0.1513 Acc: 0.9535\n",
            "Epoch  24 | Train Loss: 0.1383 Acc: 0.9564 | Val Loss: 0.1518 Acc: 0.9532\n",
            "Epoch  25 | Train Loss: 0.1352 Acc: 0.9569 | Val Loss: 0.1504 Acc: 0.9540\n",
            "Epoch  26 | Train Loss: 0.1299 Acc: 0.9581 | Val Loss: 0.1496 Acc: 0.9525\n",
            "Epoch  27 | Train Loss: 0.1291 Acc: 0.9579 | Val Loss: 0.1466 Acc: 0.9557\n",
            "Epoch  28 | Train Loss: 0.1255 Acc: 0.9604 | Val Loss: 0.1456 Acc: 0.9550\n",
            "Epoch  29 | Train Loss: 0.1205 Acc: 0.9610 | Val Loss: 0.1445 Acc: 0.9558\n",
            "Epoch  30 | Train Loss: 0.1192 Acc: 0.9617 | Val Loss: 0.1412 Acc: 0.9573\n",
            "Epoch  31 | Train Loss: 0.1104 Acc: 0.9645 | Val Loss: 0.1415 Acc: 0.9577\n",
            "Epoch  32 | Train Loss: 0.1122 Acc: 0.9635 | Val Loss: 0.1434 Acc: 0.9560\n",
            "Epoch  33 | Train Loss: 0.1091 Acc: 0.9653 | Val Loss: 0.1451 Acc: 0.9547\n",
            "Epoch  34 | Train Loss: 0.1049 Acc: 0.9657 | Val Loss: 0.1415 Acc: 0.9562\n",
            "Epoch  35 | Train Loss: 0.1029 Acc: 0.9656 | Val Loss: 0.1428 Acc: 0.9555\n",
            "Epoch  36 | Train Loss: 0.0987 Acc: 0.9678 | Val Loss: 0.1393 Acc: 0.9577\n",
            "Epoch  37 | Train Loss: 0.0979 Acc: 0.9677 | Val Loss: 0.1425 Acc: 0.9577\n",
            "Epoch  38 | Train Loss: 0.0952 Acc: 0.9695 | Val Loss: 0.1422 Acc: 0.9572\n",
            "Epoch  39 | Train Loss: 0.0913 Acc: 0.9705 | Val Loss: 0.1423 Acc: 0.9565\n",
            "Epoch  40 | Train Loss: 0.0920 Acc: 0.9701 | Val Loss: 0.1430 Acc: 0.9553\n",
            "Epoch  41 | Train Loss: 0.0888 Acc: 0.9715 | Val Loss: 0.1414 Acc: 0.9570\n",
            "Epoch  42 | Train Loss: 0.0893 Acc: 0.9708 | Val Loss: 0.1380 Acc: 0.9578\n",
            "Epoch  43 | Train Loss: 0.0842 Acc: 0.9720 | Val Loss: 0.1373 Acc: 0.9593\n",
            "Epoch  44 | Train Loss: 0.0852 Acc: 0.9723 | Val Loss: 0.1388 Acc: 0.9590\n",
            "Epoch  45 | Train Loss: 0.0823 Acc: 0.9721 | Val Loss: 0.1373 Acc: 0.9592\n",
            "Epoch  46 | Train Loss: 0.0798 Acc: 0.9734 | Val Loss: 0.1384 Acc: 0.9580\n",
            "Epoch  47 | Train Loss: 0.0794 Acc: 0.9742 | Val Loss: 0.1386 Acc: 0.9573\n",
            "Epoch  48 | Train Loss: 0.0795 Acc: 0.9741 | Val Loss: 0.1398 Acc: 0.9592\n",
            "Epoch  49 | Train Loss: 0.0738 Acc: 0.9763 | Val Loss: 0.1403 Acc: 0.9588\n",
            "Epoch  50 | Train Loss: 0.0733 Acc: 0.9756 | Val Loss: 0.1399 Acc: 0.9580\n",
            "\n",
            "ðŸ›‘ Early stopping triggered at epoch 50\n",
            "\n",
            "âœ… Training complete!\n",
            "ðŸ’¾ Model saved to exp03_deeper2_model.pt\n",
            "Train: 54000 | Val: 6000 | Test: 10000\n",
            "ðŸš€ Starting training...\n",
            "\n",
            "Epoch   1 | Train Loss: 1.8545 Acc: 0.4190 | Val Loss: 1.2269 Acc: 0.7012\n",
            "Epoch   2 | Train Loss: 1.0536 Acc: 0.7022 | Val Loss: 0.7129 Acc: 0.8005\n",
            "Epoch   3 | Train Loss: 0.7437 Acc: 0.7796 | Val Loss: 0.5185 Acc: 0.8482\n",
            "Epoch   4 | Train Loss: 0.6088 Acc: 0.8169 | Val Loss: 0.4293 Acc: 0.8760\n",
            "Epoch   5 | Train Loss: 0.5295 Acc: 0.8403 | Val Loss: 0.3712 Acc: 0.8930\n",
            "Epoch   6 | Train Loss: 0.4738 Acc: 0.8564 | Val Loss: 0.3301 Acc: 0.9018\n",
            "Epoch   7 | Train Loss: 0.4360 Acc: 0.8676 | Val Loss: 0.3054 Acc: 0.9075\n",
            "Epoch   8 | Train Loss: 0.4051 Acc: 0.8769 | Val Loss: 0.2879 Acc: 0.9128\n",
            "Epoch   9 | Train Loss: 0.3816 Acc: 0.8834 | Val Loss: 0.2682 Acc: 0.9183\n",
            "Epoch  10 | Train Loss: 0.3560 Acc: 0.8914 | Val Loss: 0.2526 Acc: 0.9228\n",
            "Epoch  11 | Train Loss: 0.3337 Acc: 0.8984 | Val Loss: 0.2421 Acc: 0.9257\n",
            "Epoch  12 | Train Loss: 0.3250 Acc: 0.9006 | Val Loss: 0.2324 Acc: 0.9282\n",
            "Epoch  13 | Train Loss: 0.3145 Acc: 0.9045 | Val Loss: 0.2204 Acc: 0.9328\n",
            "Epoch  14 | Train Loss: 0.2994 Acc: 0.9073 | Val Loss: 0.2137 Acc: 0.9323\n",
            "Epoch  15 | Train Loss: 0.2900 Acc: 0.9101 | Val Loss: 0.2096 Acc: 0.9357\n",
            "Epoch  16 | Train Loss: 0.2796 Acc: 0.9136 | Val Loss: 0.2053 Acc: 0.9380\n",
            "Epoch  17 | Train Loss: 0.2677 Acc: 0.9173 | Val Loss: 0.1976 Acc: 0.9397\n",
            "Epoch  18 | Train Loss: 0.2586 Acc: 0.9189 | Val Loss: 0.1929 Acc: 0.9413\n",
            "Epoch  19 | Train Loss: 0.2545 Acc: 0.9212 | Val Loss: 0.1906 Acc: 0.9423\n",
            "Epoch  20 | Train Loss: 0.2433 Acc: 0.9245 | Val Loss: 0.1856 Acc: 0.9442\n",
            "Epoch  21 | Train Loss: 0.2384 Acc: 0.9255 | Val Loss: 0.1795 Acc: 0.9448\n",
            "Epoch  22 | Train Loss: 0.2326 Acc: 0.9286 | Val Loss: 0.1765 Acc: 0.9467\n",
            "Epoch  23 | Train Loss: 0.2233 Acc: 0.9310 | Val Loss: 0.1737 Acc: 0.9488\n",
            "Epoch  24 | Train Loss: 0.2178 Acc: 0.9324 | Val Loss: 0.1710 Acc: 0.9490\n",
            "Epoch  25 | Train Loss: 0.2120 Acc: 0.9341 | Val Loss: 0.1700 Acc: 0.9483\n",
            "Epoch  26 | Train Loss: 0.2099 Acc: 0.9350 | Val Loss: 0.1709 Acc: 0.9490\n",
            "Epoch  27 | Train Loss: 0.2026 Acc: 0.9371 | Val Loss: 0.1678 Acc: 0.9502\n",
            "Epoch  28 | Train Loss: 0.1980 Acc: 0.9394 | Val Loss: 0.1625 Acc: 0.9520\n",
            "Epoch  29 | Train Loss: 0.1999 Acc: 0.9381 | Val Loss: 0.1608 Acc: 0.9525\n",
            "Epoch  30 | Train Loss: 0.1891 Acc: 0.9407 | Val Loss: 0.1587 Acc: 0.9527\n",
            "Epoch  31 | Train Loss: 0.1887 Acc: 0.9406 | Val Loss: 0.1583 Acc: 0.9533\n",
            "Epoch  32 | Train Loss: 0.1854 Acc: 0.9415 | Val Loss: 0.1563 Acc: 0.9537\n",
            "Epoch  33 | Train Loss: 0.1805 Acc: 0.9450 | Val Loss: 0.1553 Acc: 0.9555\n",
            "Epoch  34 | Train Loss: 0.1762 Acc: 0.9461 | Val Loss: 0.1546 Acc: 0.9537\n",
            "Epoch  35 | Train Loss: 0.1755 Acc: 0.9458 | Val Loss: 0.1551 Acc: 0.9543\n",
            "Epoch  36 | Train Loss: 0.1686 Acc: 0.9467 | Val Loss: 0.1487 Acc: 0.9553\n",
            "Epoch  37 | Train Loss: 0.1673 Acc: 0.9459 | Val Loss: 0.1507 Acc: 0.9558\n",
            "Epoch  38 | Train Loss: 0.1641 Acc: 0.9478 | Val Loss: 0.1495 Acc: 0.9562\n",
            "Epoch  39 | Train Loss: 0.1602 Acc: 0.9502 | Val Loss: 0.1501 Acc: 0.9567\n",
            "Epoch  40 | Train Loss: 0.1570 Acc: 0.9506 | Val Loss: 0.1490 Acc: 0.9558\n",
            "Epoch  41 | Train Loss: 0.1549 Acc: 0.9504 | Val Loss: 0.1457 Acc: 0.9577\n",
            "Epoch  42 | Train Loss: 0.1556 Acc: 0.9516 | Val Loss: 0.1443 Acc: 0.9597\n",
            "Epoch  43 | Train Loss: 0.1482 Acc: 0.9543 | Val Loss: 0.1453 Acc: 0.9565\n",
            "Epoch  44 | Train Loss: 0.1467 Acc: 0.9545 | Val Loss: 0.1444 Acc: 0.9585\n",
            "Epoch  45 | Train Loss: 0.1451 Acc: 0.9531 | Val Loss: 0.1432 Acc: 0.9590\n",
            "Epoch  46 | Train Loss: 0.1456 Acc: 0.9535 | Val Loss: 0.1437 Acc: 0.9577\n",
            "Epoch  47 | Train Loss: 0.1416 Acc: 0.9552 | Val Loss: 0.1427 Acc: 0.9582\n",
            "Epoch  48 | Train Loss: 0.1360 Acc: 0.9565 | Val Loss: 0.1415 Acc: 0.9595\n",
            "Epoch  49 | Train Loss: 0.1366 Acc: 0.9564 | Val Loss: 0.1420 Acc: 0.9572\n",
            "Epoch  50 | Train Loss: 0.1354 Acc: 0.9575 | Val Loss: 0.1407 Acc: 0.9585\n",
            "Epoch  51 | Train Loss: 0.1347 Acc: 0.9571 | Val Loss: 0.1398 Acc: 0.9592\n",
            "Epoch  52 | Train Loss: 0.1305 Acc: 0.9577 | Val Loss: 0.1418 Acc: 0.9587\n",
            "Epoch  53 | Train Loss: 0.1282 Acc: 0.9592 | Val Loss: 0.1407 Acc: 0.9587\n",
            "Epoch  54 | Train Loss: 0.1291 Acc: 0.9593 | Val Loss: 0.1406 Acc: 0.9588\n",
            "Epoch  55 | Train Loss: 0.1243 Acc: 0.9596 | Val Loss: 0.1405 Acc: 0.9592\n",
            "Epoch  56 | Train Loss: 0.1233 Acc: 0.9607 | Val Loss: 0.1402 Acc: 0.9595\n",
            "Epoch  57 | Train Loss: 0.1215 Acc: 0.9616 | Val Loss: 0.1434 Acc: 0.9592\n",
            "Epoch  58 | Train Loss: 0.1208 Acc: 0.9616 | Val Loss: 0.1387 Acc: 0.9615\n",
            "Epoch  59 | Train Loss: 0.1175 Acc: 0.9624 | Val Loss: 0.1402 Acc: 0.9600\n",
            "Epoch  60 | Train Loss: 0.1195 Acc: 0.9624 | Val Loss: 0.1374 Acc: 0.9598\n",
            "\n",
            "âœ… Training complete!\n",
            "ðŸ’¾ Model saved to exp04_deeper3_model.pt\n",
            "Train: 54000 | Val: 6000 | Test: 10000\n",
            "ðŸš€ Starting training...\n",
            "\n",
            "Epoch   1 | Train Loss: 1.6708 Acc: 0.4605 | Val Loss: 1.0023 Acc: 0.7345\n",
            "Epoch   2 | Train Loss: 0.9153 Acc: 0.7251 | Val Loss: 0.6379 Acc: 0.8113\n",
            "Epoch   3 | Train Loss: 0.7043 Acc: 0.7830 | Val Loss: 0.5069 Acc: 0.8463\n",
            "Epoch   4 | Train Loss: 0.6100 Acc: 0.8085 | Val Loss: 0.4297 Acc: 0.8730\n",
            "Epoch   5 | Train Loss: 0.5459 Acc: 0.8293 | Val Loss: 0.3849 Acc: 0.8843\n",
            "Epoch   6 | Train Loss: 0.4999 Acc: 0.8437 | Val Loss: 0.3505 Acc: 0.8945\n",
            "Epoch   7 | Train Loss: 0.4707 Acc: 0.8540 | Val Loss: 0.3230 Acc: 0.9022\n",
            "Epoch   8 | Train Loss: 0.4361 Acc: 0.8645 | Val Loss: 0.3027 Acc: 0.9092\n",
            "Epoch   9 | Train Loss: 0.4119 Acc: 0.8732 | Val Loss: 0.2863 Acc: 0.9140\n",
            "Epoch  10 | Train Loss: 0.3923 Acc: 0.8765 | Val Loss: 0.2744 Acc: 0.9162\n",
            "Epoch  11 | Train Loss: 0.3780 Acc: 0.8811 | Val Loss: 0.2640 Acc: 0.9220\n",
            "Epoch  12 | Train Loss: 0.3647 Acc: 0.8846 | Val Loss: 0.2525 Acc: 0.9238\n",
            "Epoch  13 | Train Loss: 0.3478 Acc: 0.8916 | Val Loss: 0.2436 Acc: 0.9275\n",
            "Epoch  14 | Train Loss: 0.3416 Acc: 0.8936 | Val Loss: 0.2358 Acc: 0.9290\n",
            "Epoch  15 | Train Loss: 0.3269 Acc: 0.8975 | Val Loss: 0.2286 Acc: 0.9312\n",
            "Epoch  16 | Train Loss: 0.3175 Acc: 0.8994 | Val Loss: 0.2242 Acc: 0.9335\n",
            "Epoch  17 | Train Loss: 0.3120 Acc: 0.9020 | Val Loss: 0.2173 Acc: 0.9335\n",
            "Epoch  18 | Train Loss: 0.2996 Acc: 0.9068 | Val Loss: 0.2130 Acc: 0.9372\n",
            "Epoch  19 | Train Loss: 0.2979 Acc: 0.9076 | Val Loss: 0.2060 Acc: 0.9373\n",
            "Epoch  20 | Train Loss: 0.2875 Acc: 0.9096 | Val Loss: 0.2018 Acc: 0.9390\n",
            "Epoch  21 | Train Loss: 0.2824 Acc: 0.9115 | Val Loss: 0.1993 Acc: 0.9405\n",
            "Epoch  22 | Train Loss: 0.2744 Acc: 0.9143 | Val Loss: 0.1970 Acc: 0.9403\n",
            "Epoch  23 | Train Loss: 0.2663 Acc: 0.9166 | Val Loss: 0.1921 Acc: 0.9425\n",
            "Epoch  24 | Train Loss: 0.2618 Acc: 0.9166 | Val Loss: 0.1899 Acc: 0.9430\n",
            "Epoch  25 | Train Loss: 0.2603 Acc: 0.9194 | Val Loss: 0.1877 Acc: 0.9437\n",
            "Epoch  26 | Train Loss: 0.2504 Acc: 0.9210 | Val Loss: 0.1835 Acc: 0.9467\n",
            "Epoch  27 | Train Loss: 0.2481 Acc: 0.9215 | Val Loss: 0.1803 Acc: 0.9478\n",
            "Epoch  28 | Train Loss: 0.2408 Acc: 0.9242 | Val Loss: 0.1783 Acc: 0.9480\n",
            "Epoch  29 | Train Loss: 0.2318 Acc: 0.9271 | Val Loss: 0.1780 Acc: 0.9457\n",
            "Epoch  30 | Train Loss: 0.2277 Acc: 0.9279 | Val Loss: 0.1768 Acc: 0.9470\n",
            "Epoch  31 | Train Loss: 0.2317 Acc: 0.9266 | Val Loss: 0.1734 Acc: 0.9487\n",
            "Epoch  32 | Train Loss: 0.2215 Acc: 0.9299 | Val Loss: 0.1717 Acc: 0.9487\n",
            "Epoch  33 | Train Loss: 0.2238 Acc: 0.9296 | Val Loss: 0.1740 Acc: 0.9485\n",
            "Epoch  34 | Train Loss: 0.2219 Acc: 0.9289 | Val Loss: 0.1697 Acc: 0.9482\n",
            "Epoch  35 | Train Loss: 0.2174 Acc: 0.9312 | Val Loss: 0.1710 Acc: 0.9480\n",
            "Epoch  36 | Train Loss: 0.2146 Acc: 0.9322 | Val Loss: 0.1672 Acc: 0.9503\n",
            "Epoch  37 | Train Loss: 0.2180 Acc: 0.9311 | Val Loss: 0.1660 Acc: 0.9510\n",
            "Epoch  38 | Train Loss: 0.2039 Acc: 0.9356 | Val Loss: 0.1636 Acc: 0.9517\n",
            "Epoch  39 | Train Loss: 0.2059 Acc: 0.9361 | Val Loss: 0.1623 Acc: 0.9520\n",
            "Epoch  40 | Train Loss: 0.2013 Acc: 0.9361 | Val Loss: 0.1625 Acc: 0.9508\n",
            "Epoch  41 | Train Loss: 0.1997 Acc: 0.9369 | Val Loss: 0.1615 Acc: 0.9520\n",
            "Epoch  42 | Train Loss: 0.1988 Acc: 0.9360 | Val Loss: 0.1614 Acc: 0.9502\n",
            "Epoch  43 | Train Loss: 0.1947 Acc: 0.9387 | Val Loss: 0.1592 Acc: 0.9523\n",
            "Epoch  44 | Train Loss: 0.1919 Acc: 0.9380 | Val Loss: 0.1589 Acc: 0.9525\n",
            "Epoch  45 | Train Loss: 0.1914 Acc: 0.9389 | Val Loss: 0.1591 Acc: 0.9533\n",
            "Epoch  46 | Train Loss: 0.1852 Acc: 0.9412 | Val Loss: 0.1563 Acc: 0.9525\n",
            "Epoch  47 | Train Loss: 0.1843 Acc: 0.9414 | Val Loss: 0.1545 Acc: 0.9543\n",
            "Epoch  48 | Train Loss: 0.1829 Acc: 0.9421 | Val Loss: 0.1557 Acc: 0.9537\n",
            "Epoch  49 | Train Loss: 0.1817 Acc: 0.9420 | Val Loss: 0.1515 Acc: 0.9553\n",
            "Epoch  50 | Train Loss: 0.1776 Acc: 0.9442 | Val Loss: 0.1536 Acc: 0.9530\n",
            "Epoch  51 | Train Loss: 0.1771 Acc: 0.9432 | Val Loss: 0.1513 Acc: 0.9535\n",
            "Epoch  52 | Train Loss: 0.1696 Acc: 0.9465 | Val Loss: 0.1501 Acc: 0.9553\n",
            "Epoch  53 | Train Loss: 0.1748 Acc: 0.9452 | Val Loss: 0.1486 Acc: 0.9553\n",
            "Epoch  54 | Train Loss: 0.1729 Acc: 0.9452 | Val Loss: 0.1495 Acc: 0.9548\n",
            "Epoch  55 | Train Loss: 0.1673 Acc: 0.9466 | Val Loss: 0.1497 Acc: 0.9550\n",
            "Epoch  56 | Train Loss: 0.1653 Acc: 0.9471 | Val Loss: 0.1505 Acc: 0.9555\n",
            "Epoch  57 | Train Loss: 0.1634 Acc: 0.9472 | Val Loss: 0.1480 Acc: 0.9560\n",
            "Epoch  58 | Train Loss: 0.1661 Acc: 0.9458 | Val Loss: 0.1496 Acc: 0.9558\n",
            "Epoch  59 | Train Loss: 0.1610 Acc: 0.9487 | Val Loss: 0.1476 Acc: 0.9565\n",
            "Epoch  60 | Train Loss: 0.1611 Acc: 0.9489 | Val Loss: 0.1482 Acc: 0.9558\n",
            "\n",
            "âœ… Training complete!\n",
            "ðŸ’¾ Model saved to exp05_dropout05_model.pt\n",
            "Train: 54000 | Val: 6000 | Test: 10000\n",
            "ðŸš€ Starting training...\n",
            "\n",
            "Epoch   1 | Train Loss: 1.4203 Acc: 0.5777 | Val Loss: 0.8259 Acc: 0.7740\n",
            "Epoch   2 | Train Loss: 0.7311 Acc: 0.7884 | Val Loss: 0.5363 Acc: 0.8368\n",
            "Epoch   3 | Train Loss: 0.5536 Acc: 0.8358 | Val Loss: 0.4250 Acc: 0.8707\n",
            "Epoch   4 | Train Loss: 0.4633 Acc: 0.8609 | Val Loss: 0.3619 Acc: 0.8912\n",
            "Epoch   5 | Train Loss: 0.4072 Acc: 0.8771 | Val Loss: 0.3183 Acc: 0.9052\n",
            "Epoch   6 | Train Loss: 0.3709 Acc: 0.8877 | Val Loss: 0.2906 Acc: 0.9153\n",
            "Epoch   7 | Train Loss: 0.3332 Acc: 0.8984 | Val Loss: 0.2662 Acc: 0.9227\n",
            "Epoch   8 | Train Loss: 0.3079 Acc: 0.9067 | Val Loss: 0.2486 Acc: 0.9285\n",
            "Epoch   9 | Train Loss: 0.2845 Acc: 0.9128 | Val Loss: 0.2342 Acc: 0.9328\n",
            "Epoch  10 | Train Loss: 0.2692 Acc: 0.9180 | Val Loss: 0.2206 Acc: 0.9347\n",
            "Epoch  11 | Train Loss: 0.2535 Acc: 0.9219 | Val Loss: 0.2137 Acc: 0.9382\n",
            "Epoch  12 | Train Loss: 0.2390 Acc: 0.9257 | Val Loss: 0.2022 Acc: 0.9400\n",
            "Epoch  13 | Train Loss: 0.2261 Acc: 0.9305 | Val Loss: 0.1967 Acc: 0.9430\n",
            "Epoch  14 | Train Loss: 0.2180 Acc: 0.9324 | Val Loss: 0.1897 Acc: 0.9445\n",
            "Epoch  15 | Train Loss: 0.2062 Acc: 0.9363 | Val Loss: 0.1836 Acc: 0.9467\n",
            "Epoch  16 | Train Loss: 0.1986 Acc: 0.9378 | Val Loss: 0.1816 Acc: 0.9473\n",
            "Epoch  17 | Train Loss: 0.1873 Acc: 0.9407 | Val Loss: 0.1747 Acc: 0.9498\n",
            "Epoch  18 | Train Loss: 0.1828 Acc: 0.9432 | Val Loss: 0.1726 Acc: 0.9507\n",
            "Epoch  19 | Train Loss: 0.1732 Acc: 0.9465 | Val Loss: 0.1692 Acc: 0.9510\n",
            "Epoch  20 | Train Loss: 0.1656 Acc: 0.9488 | Val Loss: 0.1670 Acc: 0.9517\n",
            "Epoch  21 | Train Loss: 0.1626 Acc: 0.9495 | Val Loss: 0.1643 Acc: 0.9518\n",
            "Epoch  22 | Train Loss: 0.1560 Acc: 0.9512 | Val Loss: 0.1627 Acc: 0.9538\n",
            "Epoch  23 | Train Loss: 0.1533 Acc: 0.9516 | Val Loss: 0.1582 Acc: 0.9560\n",
            "Epoch  24 | Train Loss: 0.1479 Acc: 0.9527 | Val Loss: 0.1592 Acc: 0.9560\n",
            "Epoch  25 | Train Loss: 0.1371 Acc: 0.9561 | Val Loss: 0.1539 Acc: 0.9568\n",
            "Epoch  26 | Train Loss: 0.1360 Acc: 0.9565 | Val Loss: 0.1541 Acc: 0.9550\n",
            "Epoch  27 | Train Loss: 0.1332 Acc: 0.9577 | Val Loss: 0.1509 Acc: 0.9562\n",
            "Epoch  28 | Train Loss: 0.1277 Acc: 0.9584 | Val Loss: 0.1506 Acc: 0.9570\n",
            "Epoch  29 | Train Loss: 0.1232 Acc: 0.9598 | Val Loss: 0.1518 Acc: 0.9570\n",
            "Epoch  30 | Train Loss: 0.1217 Acc: 0.9613 | Val Loss: 0.1477 Acc: 0.9573\n",
            "Epoch  31 | Train Loss: 0.1187 Acc: 0.9622 | Val Loss: 0.1512 Acc: 0.9568\n",
            "Epoch  32 | Train Loss: 0.1144 Acc: 0.9630 | Val Loss: 0.1471 Acc: 0.9560\n",
            "Epoch  33 | Train Loss: 0.1111 Acc: 0.9645 | Val Loss: 0.1480 Acc: 0.9575\n",
            "Epoch  34 | Train Loss: 0.1093 Acc: 0.9649 | Val Loss: 0.1447 Acc: 0.9582\n",
            "Epoch  35 | Train Loss: 0.1045 Acc: 0.9660 | Val Loss: 0.1435 Acc: 0.9587\n",
            "Epoch  36 | Train Loss: 0.1025 Acc: 0.9659 | Val Loss: 0.1463 Acc: 0.9575\n",
            "Epoch  37 | Train Loss: 0.0994 Acc: 0.9680 | Val Loss: 0.1459 Acc: 0.9572\n",
            "Epoch  38 | Train Loss: 0.0962 Acc: 0.9686 | Val Loss: 0.1429 Acc: 0.9602\n",
            "Epoch  39 | Train Loss: 0.0988 Acc: 0.9678 | Val Loss: 0.1405 Acc: 0.9610\n",
            "Epoch  40 | Train Loss: 0.0935 Acc: 0.9684 | Val Loss: 0.1401 Acc: 0.9600\n",
            "Epoch  41 | Train Loss: 0.0930 Acc: 0.9700 | Val Loss: 0.1434 Acc: 0.9595\n",
            "Epoch  42 | Train Loss: 0.0887 Acc: 0.9715 | Val Loss: 0.1401 Acc: 0.9608\n",
            "Epoch  43 | Train Loss: 0.0861 Acc: 0.9719 | Val Loss: 0.1395 Acc: 0.9602\n",
            "Epoch  44 | Train Loss: 0.0856 Acc: 0.9724 | Val Loss: 0.1417 Acc: 0.9610\n",
            "Epoch  45 | Train Loss: 0.0866 Acc: 0.9714 | Val Loss: 0.1411 Acc: 0.9597\n",
            "Epoch  46 | Train Loss: 0.0807 Acc: 0.9739 | Val Loss: 0.1401 Acc: 0.9597\n",
            "Epoch  47 | Train Loss: 0.0811 Acc: 0.9744 | Val Loss: 0.1416 Acc: 0.9605\n",
            "Epoch  48 | Train Loss: 0.0778 Acc: 0.9746 | Val Loss: 0.1408 Acc: 0.9593\n",
            "Epoch  49 | Train Loss: 0.0780 Acc: 0.9740 | Val Loss: 0.1413 Acc: 0.9600\n",
            "Epoch  50 | Train Loss: 0.0752 Acc: 0.9751 | Val Loss: 0.1384 Acc: 0.9617\n",
            "Epoch  51 | Train Loss: 0.0728 Acc: 0.9753 | Val Loss: 0.1398 Acc: 0.9607\n",
            "Epoch  52 | Train Loss: 0.0740 Acc: 0.9757 | Val Loss: 0.1421 Acc: 0.9597\n",
            "Epoch  53 | Train Loss: 0.0752 Acc: 0.9751 | Val Loss: 0.1390 Acc: 0.9618\n",
            "Epoch  54 | Train Loss: 0.0708 Acc: 0.9771 | Val Loss: 0.1410 Acc: 0.9618\n",
            "Epoch  55 | Train Loss: 0.0705 Acc: 0.9762 | Val Loss: 0.1416 Acc: 0.9623\n",
            "Epoch  56 | Train Loss: 0.0675 Acc: 0.9777 | Val Loss: 0.1401 Acc: 0.9620\n",
            "Epoch  57 | Train Loss: 0.0655 Acc: 0.9785 | Val Loss: 0.1381 Acc: 0.9613\n",
            "Epoch  58 | Train Loss: 0.0652 Acc: 0.9790 | Val Loss: 0.1393 Acc: 0.9622\n",
            "Epoch  59 | Train Loss: 0.0636 Acc: 0.9787 | Val Loss: 0.1386 Acc: 0.9628\n",
            "Epoch  60 | Train Loss: 0.0634 Acc: 0.9786 | Val Loss: 0.1387 Acc: 0.9623\n",
            "\n",
            "âœ… Training complete!\n",
            "ðŸ’¾ Model saved to exp06_weightdecay_model.pt\n",
            "Train: 54000 | Val: 6000 | Test: 10000\n",
            "ðŸš€ Starting training...\n",
            "\n",
            "Epoch   1 | Train Loss: 1.7098 Acc: 0.4808 | Val Loss: 1.1861 Acc: 0.6697\n",
            "Epoch   2 | Train Loss: 1.0397 Acc: 0.6976 | Val Loss: 0.7973 Acc: 0.7773\n",
            "Epoch   3 | Train Loss: 0.7775 Acc: 0.7713 | Val Loss: 0.6178 Acc: 0.8217\n",
            "Epoch   4 | Train Loss: 0.6433 Acc: 0.8075 | Val Loss: 0.5200 Acc: 0.8475\n",
            "Epoch   5 | Train Loss: 0.5585 Acc: 0.8312 | Val Loss: 0.4541 Acc: 0.8648\n",
            "Epoch   6 | Train Loss: 0.5041 Acc: 0.8469 | Val Loss: 0.4068 Acc: 0.8813\n",
            "Epoch   7 | Train Loss: 0.4588 Acc: 0.8620 | Val Loss: 0.3742 Acc: 0.8910\n",
            "Epoch   8 | Train Loss: 0.4277 Acc: 0.8693 | Val Loss: 0.3471 Acc: 0.8975\n",
            "Epoch   9 | Train Loss: 0.4004 Acc: 0.8792 | Val Loss: 0.3249 Acc: 0.9025\n",
            "Epoch  10 | Train Loss: 0.3739 Acc: 0.8862 | Val Loss: 0.3066 Acc: 0.9080\n",
            "Epoch  11 | Train Loss: 0.3507 Acc: 0.8929 | Val Loss: 0.2914 Acc: 0.9130\n",
            "Epoch  12 | Train Loss: 0.3399 Acc: 0.8948 | Val Loss: 0.2788 Acc: 0.9152\n",
            "Epoch  13 | Train Loss: 0.3226 Acc: 0.9004 | Val Loss: 0.2670 Acc: 0.9200\n",
            "Epoch  14 | Train Loss: 0.3065 Acc: 0.9061 | Val Loss: 0.2556 Acc: 0.9237\n",
            "Epoch  15 | Train Loss: 0.2972 Acc: 0.9090 | Val Loss: 0.2474 Acc: 0.9263\n",
            "Epoch  16 | Train Loss: 0.2841 Acc: 0.9128 | Val Loss: 0.2396 Acc: 0.9287\n",
            "Epoch  17 | Train Loss: 0.2770 Acc: 0.9144 | Val Loss: 0.2322 Acc: 0.9315\n",
            "Epoch  18 | Train Loss: 0.2662 Acc: 0.9174 | Val Loss: 0.2264 Acc: 0.9317\n",
            "Epoch  19 | Train Loss: 0.2561 Acc: 0.9211 | Val Loss: 0.2198 Acc: 0.9332\n",
            "Epoch  20 | Train Loss: 0.2470 Acc: 0.9242 | Val Loss: 0.2163 Acc: 0.9353\n",
            "Epoch  21 | Train Loss: 0.2401 Acc: 0.9262 | Val Loss: 0.2103 Acc: 0.9358\n",
            "Epoch  22 | Train Loss: 0.2346 Acc: 0.9269 | Val Loss: 0.2060 Acc: 0.9395\n",
            "Epoch  23 | Train Loss: 0.2299 Acc: 0.9275 | Val Loss: 0.2014 Acc: 0.9382\n",
            "Epoch  24 | Train Loss: 0.2188 Acc: 0.9318 | Val Loss: 0.1997 Acc: 0.9417\n",
            "Epoch  25 | Train Loss: 0.2161 Acc: 0.9323 | Val Loss: 0.1947 Acc: 0.9418\n",
            "Epoch  26 | Train Loss: 0.2083 Acc: 0.9357 | Val Loss: 0.1891 Acc: 0.9437\n",
            "Epoch  27 | Train Loss: 0.2023 Acc: 0.9367 | Val Loss: 0.1866 Acc: 0.9435\n",
            "Epoch  28 | Train Loss: 0.1978 Acc: 0.9386 | Val Loss: 0.1844 Acc: 0.9445\n",
            "Epoch  29 | Train Loss: 0.1920 Acc: 0.9394 | Val Loss: 0.1814 Acc: 0.9457\n",
            "Epoch  30 | Train Loss: 0.1908 Acc: 0.9411 | Val Loss: 0.1790 Acc: 0.9457\n",
            "Epoch  31 | Train Loss: 0.1848 Acc: 0.9429 | Val Loss: 0.1770 Acc: 0.9463\n",
            "Epoch  32 | Train Loss: 0.1775 Acc: 0.9439 | Val Loss: 0.1756 Acc: 0.9480\n",
            "Epoch  33 | Train Loss: 0.1733 Acc: 0.9451 | Val Loss: 0.1747 Acc: 0.9465\n",
            "Epoch  34 | Train Loss: 0.1738 Acc: 0.9445 | Val Loss: 0.1702 Acc: 0.9478\n",
            "Epoch  35 | Train Loss: 0.1682 Acc: 0.9471 | Val Loss: 0.1687 Acc: 0.9487\n",
            "Epoch  36 | Train Loss: 0.1647 Acc: 0.9485 | Val Loss: 0.1672 Acc: 0.9490\n",
            "Epoch  37 | Train Loss: 0.1633 Acc: 0.9471 | Val Loss: 0.1658 Acc: 0.9497\n",
            "Epoch  38 | Train Loss: 0.1616 Acc: 0.9480 | Val Loss: 0.1626 Acc: 0.9493\n",
            "Epoch  39 | Train Loss: 0.1556 Acc: 0.9504 | Val Loss: 0.1628 Acc: 0.9500\n",
            "Epoch  40 | Train Loss: 0.1545 Acc: 0.9512 | Val Loss: 0.1625 Acc: 0.9512\n",
            "Epoch  41 | Train Loss: 0.1499 Acc: 0.9517 | Val Loss: 0.1621 Acc: 0.9513\n",
            "Epoch  42 | Train Loss: 0.1478 Acc: 0.9533 | Val Loss: 0.1583 Acc: 0.9507\n",
            "Epoch  43 | Train Loss: 0.1434 Acc: 0.9539 | Val Loss: 0.1585 Acc: 0.9523\n",
            "Epoch  44 | Train Loss: 0.1403 Acc: 0.9547 | Val Loss: 0.1592 Acc: 0.9528\n",
            "Epoch  45 | Train Loss: 0.1354 Acc: 0.9567 | Val Loss: 0.1581 Acc: 0.9518\n",
            "Epoch  46 | Train Loss: 0.1375 Acc: 0.9555 | Val Loss: 0.1574 Acc: 0.9517\n",
            "Epoch  47 | Train Loss: 0.1332 Acc: 0.9564 | Val Loss: 0.1559 Acc: 0.9532\n",
            "Epoch  48 | Train Loss: 0.1335 Acc: 0.9570 | Val Loss: 0.1537 Acc: 0.9542\n",
            "Epoch  49 | Train Loss: 0.1279 Acc: 0.9599 | Val Loss: 0.1525 Acc: 0.9535\n",
            "Epoch  50 | Train Loss: 0.1300 Acc: 0.9584 | Val Loss: 0.1531 Acc: 0.9522\n",
            "Epoch  51 | Train Loss: 0.1269 Acc: 0.9586 | Val Loss: 0.1551 Acc: 0.9530\n",
            "Epoch  52 | Train Loss: 0.1230 Acc: 0.9601 | Val Loss: 0.1515 Acc: 0.9550\n",
            "Epoch  53 | Train Loss: 0.1189 Acc: 0.9618 | Val Loss: 0.1519 Acc: 0.9553\n",
            "Epoch  54 | Train Loss: 0.1182 Acc: 0.9627 | Val Loss: 0.1496 Acc: 0.9558\n",
            "Epoch  55 | Train Loss: 0.1177 Acc: 0.9621 | Val Loss: 0.1509 Acc: 0.9552\n",
            "Epoch  56 | Train Loss: 0.1133 Acc: 0.9638 | Val Loss: 0.1480 Acc: 0.9550\n",
            "Epoch  57 | Train Loss: 0.1137 Acc: 0.9627 | Val Loss: 0.1500 Acc: 0.9532\n",
            "Epoch  58 | Train Loss: 0.1145 Acc: 0.9632 | Val Loss: 0.1502 Acc: 0.9542\n",
            "Epoch  59 | Train Loss: 0.1096 Acc: 0.9655 | Val Loss: 0.1491 Acc: 0.9548\n",
            "Epoch  60 | Train Loss: 0.1107 Acc: 0.9649 | Val Loss: 0.1483 Acc: 0.9550\n",
            "Epoch  61 | Train Loss: 0.1063 Acc: 0.9657 | Val Loss: 0.1491 Acc: 0.9547\n",
            "Epoch  62 | Train Loss: 0.1078 Acc: 0.9649 | Val Loss: 0.1482 Acc: 0.9543\n",
            "Epoch  63 | Train Loss: 0.1051 Acc: 0.9658 | Val Loss: 0.1470 Acc: 0.9555\n",
            "Epoch  64 | Train Loss: 0.1017 Acc: 0.9666 | Val Loss: 0.1462 Acc: 0.9555\n",
            "Epoch  65 | Train Loss: 0.1025 Acc: 0.9671 | Val Loss: 0.1476 Acc: 0.9557\n",
            "Epoch  66 | Train Loss: 0.1002 Acc: 0.9668 | Val Loss: 0.1457 Acc: 0.9558\n",
            "Epoch  67 | Train Loss: 0.0967 Acc: 0.9686 | Val Loss: 0.1458 Acc: 0.9562\n",
            "Epoch  68 | Train Loss: 0.0972 Acc: 0.9685 | Val Loss: 0.1447 Acc: 0.9568\n",
            "Epoch  69 | Train Loss: 0.0938 Acc: 0.9702 | Val Loss: 0.1457 Acc: 0.9570\n",
            "Epoch  70 | Train Loss: 0.0936 Acc: 0.9691 | Val Loss: 0.1432 Acc: 0.9587\n",
            "\n",
            "âœ… Training complete!\n",
            "ðŸ’¾ Model saved to exp07_lr_low_model.pt\n",
            "Train: 54000 | Val: 6000 | Test: 10000\n",
            "ðŸš€ Starting training...\n",
            "\n",
            "Epoch   1 | Train Loss: 1.0601 Acc: 0.6841 | Val Loss: 0.5060 Acc: 0.8518\n",
            "Epoch   2 | Train Loss: 0.5027 Acc: 0.8466 | Val Loss: 0.3412 Acc: 0.8995\n",
            "Epoch   3 | Train Loss: 0.3903 Acc: 0.8801 | Val Loss: 0.2799 Acc: 0.9158\n",
            "Epoch   4 | Train Loss: 0.3334 Acc: 0.8981 | Val Loss: 0.2439 Acc: 0.9255\n",
            "Epoch   5 | Train Loss: 0.2921 Acc: 0.9094 | Val Loss: 0.2178 Acc: 0.9335\n",
            "Epoch   6 | Train Loss: 0.2635 Acc: 0.9178 | Val Loss: 0.2034 Acc: 0.9387\n",
            "Epoch   7 | Train Loss: 0.2401 Acc: 0.9253 | Val Loss: 0.1937 Acc: 0.9433\n",
            "Epoch   8 | Train Loss: 0.2206 Acc: 0.9321 | Val Loss: 0.1863 Acc: 0.9450\n",
            "Epoch   9 | Train Loss: 0.2077 Acc: 0.9358 | Val Loss: 0.1729 Acc: 0.9483\n",
            "Epoch  10 | Train Loss: 0.1973 Acc: 0.9371 | Val Loss: 0.1731 Acc: 0.9470\n",
            "Epoch  11 | Train Loss: 0.1832 Acc: 0.9413 | Val Loss: 0.1653 Acc: 0.9502\n",
            "Epoch  12 | Train Loss: 0.1700 Acc: 0.9462 | Val Loss: 0.1576 Acc: 0.9528\n",
            "Epoch  13 | Train Loss: 0.1634 Acc: 0.9479 | Val Loss: 0.1560 Acc: 0.9528\n",
            "Epoch  14 | Train Loss: 0.1607 Acc: 0.9490 | Val Loss: 0.1537 Acc: 0.9548\n",
            "Epoch  15 | Train Loss: 0.1472 Acc: 0.9526 | Val Loss: 0.1512 Acc: 0.9550\n",
            "Epoch  16 | Train Loss: 0.1434 Acc: 0.9536 | Val Loss: 0.1498 Acc: 0.9548\n",
            "Epoch  17 | Train Loss: 0.1386 Acc: 0.9561 | Val Loss: 0.1445 Acc: 0.9565\n",
            "Epoch  18 | Train Loss: 0.1331 Acc: 0.9574 | Val Loss: 0.1431 Acc: 0.9578\n",
            "Epoch  19 | Train Loss: 0.1282 Acc: 0.9580 | Val Loss: 0.1408 Acc: 0.9597\n",
            "Epoch  20 | Train Loss: 0.1189 Acc: 0.9614 | Val Loss: 0.1400 Acc: 0.9590\n",
            "Epoch  21 | Train Loss: 0.1169 Acc: 0.9618 | Val Loss: 0.1375 Acc: 0.9588\n",
            "Epoch  22 | Train Loss: 0.1186 Acc: 0.9610 | Val Loss: 0.1406 Acc: 0.9595\n",
            "Epoch  23 | Train Loss: 0.1117 Acc: 0.9636 | Val Loss: 0.1395 Acc: 0.9590\n",
            "Epoch  24 | Train Loss: 0.1056 Acc: 0.9657 | Val Loss: 0.1388 Acc: 0.9612\n",
            "Epoch  25 | Train Loss: 0.1050 Acc: 0.9655 | Val Loss: 0.1383 Acc: 0.9588\n",
            "Epoch  26 | Train Loss: 0.1005 Acc: 0.9671 | Val Loss: 0.1386 Acc: 0.9598\n",
            "Epoch  27 | Train Loss: 0.0994 Acc: 0.9677 | Val Loss: 0.1413 Acc: 0.9598\n",
            "Epoch  28 | Train Loss: 0.0964 Acc: 0.9682 | Val Loss: 0.1418 Acc: 0.9592\n",
            "Epoch  29 | Train Loss: 0.0899 Acc: 0.9704 | Val Loss: 0.1399 Acc: 0.9620\n",
            "\n",
            "ðŸ›‘ Early stopping triggered at epoch 29\n",
            "\n",
            "âœ… Training complete!\n",
            "ðŸ’¾ Model saved to exp08_batch64_model.pt\n",
            "Train: 54000 | Val: 6000 | Test: 10000\n",
            "ðŸš€ Starting training...\n",
            "\n",
            "Epoch   1 | Train Loss: 1.7105 Acc: 0.4651 | Val Loss: 1.1903 Acc: 0.6728\n",
            "Epoch   2 | Train Loss: 1.0159 Acc: 0.7148 | Val Loss: 0.7827 Acc: 0.7865\n",
            "Epoch   3 | Train Loss: 0.7312 Acc: 0.7914 | Val Loss: 0.5906 Acc: 0.8322\n",
            "Epoch   4 | Train Loss: 0.5878 Acc: 0.8269 | Val Loss: 0.4867 Acc: 0.8558\n",
            "Epoch   5 | Train Loss: 0.5065 Acc: 0.8483 | Val Loss: 0.4224 Acc: 0.8718\n",
            "Epoch   6 | Train Loss: 0.4458 Acc: 0.8669 | Val Loss: 0.3764 Acc: 0.8848\n",
            "Epoch   7 | Train Loss: 0.4028 Acc: 0.8784 | Val Loss: 0.3425 Acc: 0.8957\n",
            "Epoch   8 | Train Loss: 0.3696 Acc: 0.8889 | Val Loss: 0.3171 Acc: 0.9052\n",
            "Epoch   9 | Train Loss: 0.3468 Acc: 0.8945 | Val Loss: 0.2954 Acc: 0.9118\n",
            "Epoch  10 | Train Loss: 0.3231 Acc: 0.9035 | Val Loss: 0.2763 Acc: 0.9182\n",
            "Epoch  11 | Train Loss: 0.3060 Acc: 0.9066 | Val Loss: 0.2627 Acc: 0.9225\n",
            "Epoch  12 | Train Loss: 0.2906 Acc: 0.9113 | Val Loss: 0.2492 Acc: 0.9242\n",
            "Epoch  13 | Train Loss: 0.2712 Acc: 0.9181 | Val Loss: 0.2376 Acc: 0.9300\n",
            "Epoch  14 | Train Loss: 0.2608 Acc: 0.9213 | Val Loss: 0.2278 Acc: 0.9317\n",
            "Epoch  15 | Train Loss: 0.2497 Acc: 0.9228 | Val Loss: 0.2175 Acc: 0.9335\n",
            "Epoch  16 | Train Loss: 0.2368 Acc: 0.9275 | Val Loss: 0.2113 Acc: 0.9362\n",
            "Epoch  17 | Train Loss: 0.2283 Acc: 0.9301 | Val Loss: 0.2050 Acc: 0.9373\n",
            "Epoch  18 | Train Loss: 0.2211 Acc: 0.9323 | Val Loss: 0.1992 Acc: 0.9393\n",
            "Epoch  19 | Train Loss: 0.2118 Acc: 0.9353 | Val Loss: 0.1972 Acc: 0.9408\n",
            "Epoch  20 | Train Loss: 0.2008 Acc: 0.9378 | Val Loss: 0.1896 Acc: 0.9423\n",
            "Epoch  21 | Train Loss: 0.1969 Acc: 0.9390 | Val Loss: 0.1832 Acc: 0.9442\n",
            "Epoch  22 | Train Loss: 0.1902 Acc: 0.9406 | Val Loss: 0.1808 Acc: 0.9450\n",
            "Epoch  23 | Train Loss: 0.1830 Acc: 0.9438 | Val Loss: 0.1757 Acc: 0.9465\n",
            "Epoch  24 | Train Loss: 0.1772 Acc: 0.9448 | Val Loss: 0.1726 Acc: 0.9463\n",
            "Epoch  25 | Train Loss: 0.1720 Acc: 0.9473 | Val Loss: 0.1695 Acc: 0.9475\n",
            "Epoch  26 | Train Loss: 0.1669 Acc: 0.9472 | Val Loss: 0.1680 Acc: 0.9487\n",
            "Epoch  27 | Train Loss: 0.1593 Acc: 0.9502 | Val Loss: 0.1651 Acc: 0.9483\n",
            "Epoch  28 | Train Loss: 0.1570 Acc: 0.9513 | Val Loss: 0.1622 Acc: 0.9490\n",
            "Epoch  29 | Train Loss: 0.1531 Acc: 0.9517 | Val Loss: 0.1617 Acc: 0.9495\n",
            "Epoch  30 | Train Loss: 0.1488 Acc: 0.9547 | Val Loss: 0.1579 Acc: 0.9520\n",
            "Epoch  31 | Train Loss: 0.1456 Acc: 0.9541 | Val Loss: 0.1551 Acc: 0.9527\n",
            "Epoch  32 | Train Loss: 0.1408 Acc: 0.9559 | Val Loss: 0.1541 Acc: 0.9522\n",
            "Epoch  33 | Train Loss: 0.1398 Acc: 0.9560 | Val Loss: 0.1532 Acc: 0.9513\n",
            "Epoch  34 | Train Loss: 0.1354 Acc: 0.9576 | Val Loss: 0.1509 Acc: 0.9530\n",
            "Epoch  35 | Train Loss: 0.1290 Acc: 0.9598 | Val Loss: 0.1492 Acc: 0.9537\n",
            "Epoch  36 | Train Loss: 0.1287 Acc: 0.9584 | Val Loss: 0.1484 Acc: 0.9553\n",
            "Epoch  37 | Train Loss: 0.1261 Acc: 0.9599 | Val Loss: 0.1490 Acc: 0.9542\n",
            "Epoch  38 | Train Loss: 0.1207 Acc: 0.9620 | Val Loss: 0.1447 Acc: 0.9560\n",
            "Epoch  39 | Train Loss: 0.1182 Acc: 0.9629 | Val Loss: 0.1454 Acc: 0.9562\n",
            "Epoch  40 | Train Loss: 0.1155 Acc: 0.9633 | Val Loss: 0.1448 Acc: 0.9550\n",
            "Epoch  41 | Train Loss: 0.1150 Acc: 0.9642 | Val Loss: 0.1416 Acc: 0.9558\n",
            "Epoch  42 | Train Loss: 0.1083 Acc: 0.9662 | Val Loss: 0.1432 Acc: 0.9570\n",
            "Epoch  43 | Train Loss: 0.1091 Acc: 0.9657 | Val Loss: 0.1401 Acc: 0.9582\n",
            "Epoch  44 | Train Loss: 0.1035 Acc: 0.9665 | Val Loss: 0.1384 Acc: 0.9572\n",
            "Epoch  45 | Train Loss: 0.1025 Acc: 0.9676 | Val Loss: 0.1387 Acc: 0.9578\n",
            "Epoch  46 | Train Loss: 0.1013 Acc: 0.9680 | Val Loss: 0.1388 Acc: 0.9578\n",
            "Epoch  47 | Train Loss: 0.0976 Acc: 0.9690 | Val Loss: 0.1392 Acc: 0.9587\n",
            "Epoch  48 | Train Loss: 0.0973 Acc: 0.9690 | Val Loss: 0.1394 Acc: 0.9587\n",
            "Epoch  49 | Train Loss: 0.0951 Acc: 0.9698 | Val Loss: 0.1368 Acc: 0.9578\n",
            "Epoch  50 | Train Loss: 0.0934 Acc: 0.9701 | Val Loss: 0.1372 Acc: 0.9597\n",
            "\n",
            "âœ… Training complete!\n",
            "ðŸ’¾ Model saved to exp09_batch256_model.pt\n",
            "Train: 54000 | Val: 6000 | Test: 10000\n",
            "ðŸš€ Starting training...\n",
            "\n",
            "Epoch   1 | Train Loss: 1.5065 Acc: 0.5605 | Val Loss: 0.9190 Acc: 0.7568\n",
            "Epoch   2 | Train Loss: 0.7775 Acc: 0.7812 | Val Loss: 0.5790 Acc: 0.8322\n",
            "Epoch   3 | Train Loss: 0.5691 Acc: 0.8307 | Val Loss: 0.4464 Acc: 0.8707\n",
            "Epoch   4 | Train Loss: 0.4682 Acc: 0.8607 | Val Loss: 0.3715 Acc: 0.8920\n",
            "Epoch   5 | Train Loss: 0.4011 Acc: 0.8787 | Val Loss: 0.3202 Acc: 0.9043\n",
            "Epoch   6 | Train Loss: 0.3561 Acc: 0.8935 | Val Loss: 0.2860 Acc: 0.9138\n",
            "Epoch   7 | Train Loss: 0.3234 Acc: 0.9014 | Val Loss: 0.2613 Acc: 0.9218\n",
            "Epoch   8 | Train Loss: 0.2987 Acc: 0.9088 | Val Loss: 0.2415 Acc: 0.9265\n",
            "Epoch   9 | Train Loss: 0.2737 Acc: 0.9180 | Val Loss: 0.2269 Acc: 0.9317\n",
            "Epoch  10 | Train Loss: 0.2535 Acc: 0.9234 | Val Loss: 0.2141 Acc: 0.9357\n",
            "Epoch  11 | Train Loss: 0.2404 Acc: 0.9265 | Val Loss: 0.2041 Acc: 0.9400\n",
            "Epoch  12 | Train Loss: 0.2288 Acc: 0.9299 | Val Loss: 0.1980 Acc: 0.9407\n",
            "Epoch  13 | Train Loss: 0.2159 Acc: 0.9337 | Val Loss: 0.1910 Acc: 0.9432\n",
            "Epoch  14 | Train Loss: 0.2033 Acc: 0.9363 | Val Loss: 0.1877 Acc: 0.9438\n",
            "Epoch  15 | Train Loss: 0.1963 Acc: 0.9397 | Val Loss: 0.1813 Acc: 0.9465\n",
            "Epoch  16 | Train Loss: 0.1862 Acc: 0.9414 | Val Loss: 0.1786 Acc: 0.9458\n",
            "Epoch  17 | Train Loss: 0.1797 Acc: 0.9439 | Val Loss: 0.1734 Acc: 0.9487\n",
            "Epoch  18 | Train Loss: 0.1754 Acc: 0.9446 | Val Loss: 0.1732 Acc: 0.9502\n",
            "Epoch  19 | Train Loss: 0.1669 Acc: 0.9469 | Val Loss: 0.1714 Acc: 0.9495\n",
            "Epoch  20 | Train Loss: 0.1618 Acc: 0.9484 | Val Loss: 0.1709 Acc: 0.9522\n",
            "Epoch  21 | Train Loss: 0.1565 Acc: 0.9510 | Val Loss: 0.1638 Acc: 0.9517\n",
            "Epoch  22 | Train Loss: 0.1505 Acc: 0.9511 | Val Loss: 0.1646 Acc: 0.9517\n",
            "Epoch  23 | Train Loss: 0.1474 Acc: 0.9521 | Val Loss: 0.1617 Acc: 0.9532\n",
            "Epoch  24 | Train Loss: 0.1405 Acc: 0.9548 | Val Loss: 0.1599 Acc: 0.9552\n",
            "Epoch  25 | Train Loss: 0.1378 Acc: 0.9559 | Val Loss: 0.1565 Acc: 0.9545\n",
            "Epoch  26 | Train Loss: 0.1330 Acc: 0.9575 | Val Loss: 0.1587 Acc: 0.9530\n",
            "Epoch  27 | Train Loss: 0.1275 Acc: 0.9586 | Val Loss: 0.1544 Acc: 0.9562\n",
            "Epoch  28 | Train Loss: 0.1242 Acc: 0.9606 | Val Loss: 0.1563 Acc: 0.9525\n",
            "Epoch  29 | Train Loss: 0.1224 Acc: 0.9606 | Val Loss: 0.1531 Acc: 0.9563\n",
            "Epoch  30 | Train Loss: 0.1207 Acc: 0.9606 | Val Loss: 0.1520 Acc: 0.9558\n",
            "Epoch  31 | Train Loss: 0.1156 Acc: 0.9627 | Val Loss: 0.1501 Acc: 0.9575\n",
            "Epoch  32 | Train Loss: 0.1148 Acc: 0.9628 | Val Loss: 0.1531 Acc: 0.9558\n",
            "Epoch  33 | Train Loss: 0.1136 Acc: 0.9625 | Val Loss: 0.1490 Acc: 0.9577\n",
            "Epoch  34 | Train Loss: 0.1094 Acc: 0.9643 | Val Loss: 0.1522 Acc: 0.9572\n",
            "Epoch  35 | Train Loss: 0.1028 Acc: 0.9667 | Val Loss: 0.1517 Acc: 0.9550\n",
            "Epoch  36 | Train Loss: 0.1045 Acc: 0.9662 | Val Loss: 0.1497 Acc: 0.9563\n",
            "Epoch  37 | Train Loss: 0.1001 Acc: 0.9674 | Val Loss: 0.1498 Acc: 0.9552\n",
            "Epoch  38 | Train Loss: 0.1008 Acc: 0.9669 | Val Loss: 0.1516 Acc: 0.9573\n",
            "Epoch  39 | Train Loss: 0.0995 Acc: 0.9675 | Val Loss: 0.1525 Acc: 0.9563\n",
            "Epoch  40 | Train Loss: 0.0988 Acc: 0.9682 | Val Loss: 0.1512 Acc: 0.9575\n",
            "\n",
            "ðŸ›‘ Early stopping triggered at epoch 40\n",
            "\n",
            "âœ… Training complete!\n",
            "ðŸ’¾ Model saved to exp10_small_model.pt\n",
            "âœ… Finished 10 experiments.\n",
            "ðŸ† Best experiment: exp06_weightdecay (best_val_acc=0.9628)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          experiment  batch_size  epochs      lr  patience  best_val_acc  \\\n",
              "5  exp06_weightdecay         128      60  0.0010         8      0.962833   \n",
              "7      exp08_batch64          64      60  0.0010         8      0.962000   \n",
              "3      exp04_deeper3         128      60  0.0008         8      0.961500   \n",
              "8     exp09_batch256         256      50  0.0010         7      0.959667   \n",
              "2      exp03_deeper2         128      50  0.0010         7      0.959333   \n",
              "6       exp07_lr_low         128      70  0.0005        10      0.958667   \n",
              "9        exp10_small         128      50  0.0010         7      0.957667   \n",
              "4    exp05_dropout05         128      60  0.0010         8      0.956500   \n",
              "1        exp02_wider         128      40  0.0010         6      0.954833   \n",
              "0     exp01_baseline         128      40  0.0010         6      0.951833   \n",
              "\n",
              "   train_acc  test_acc                                             layers  \n",
              "5   0.998815    0.9051  [(512, 0.3, True, 0.0001), (256, 0.3, True, 0....  \n",
              "7   0.996185    0.9033  [(512, 0.3, True, 0.0), (256, 0.3, True, 0.0),...  \n",
              "3   0.993778    0.9015  [(512, 0.35, True, 0.0), (256, 0.35, True, 0.0...  \n",
              "8   0.993944    0.8970  [(512, 0.25, True, 0.0), (256, 0.25, True, 0.0...  \n",
              "2   0.997889    0.9008  [(512, 0.3, True, 0.0), (256, 0.3, True, 0.0),...  \n",
              "6   0.995370    0.9021  [(512, 0.3, True, 0.0001), (256, 0.3, True, 0....  \n",
              "9   0.995130    0.8938  [(256, 0.2, True, 0.0), (128, 0.2, True, 0.0),...  \n",
              "4   0.987315    0.8919  [(512, 0.5, True, 0.0), (256, 0.5, True, 0.0),...  \n",
              "1   0.996167    0.8931    [(512, 0.25, True, 0.0), (10, 0.0, False, 0.0)]  \n",
              "0   0.993444    0.8841     [(256, 0.2, True, 0.0), (10, 0.0, False, 0.0)]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38ef7ca5-2c7d-47b8-8524-e2ac9a97cf00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>experiment</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>lr</th>\n",
              "      <th>patience</th>\n",
              "      <th>best_val_acc</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>layers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>exp06_weightdecay</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>8</td>\n",
              "      <td>0.962833</td>\n",
              "      <td>0.998815</td>\n",
              "      <td>0.9051</td>\n",
              "      <td>[(512, 0.3, True, 0.0001), (256, 0.3, True, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>exp08_batch64</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>8</td>\n",
              "      <td>0.962000</td>\n",
              "      <td>0.996185</td>\n",
              "      <td>0.9033</td>\n",
              "      <td>[(512, 0.3, True, 0.0), (256, 0.3, True, 0.0),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>exp04_deeper3</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>8</td>\n",
              "      <td>0.961500</td>\n",
              "      <td>0.993778</td>\n",
              "      <td>0.9015</td>\n",
              "      <td>[(512, 0.35, True, 0.0), (256, 0.35, True, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>exp09_batch256</td>\n",
              "      <td>256</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>7</td>\n",
              "      <td>0.959667</td>\n",
              "      <td>0.993944</td>\n",
              "      <td>0.8970</td>\n",
              "      <td>[(512, 0.25, True, 0.0), (256, 0.25, True, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>exp03_deeper2</td>\n",
              "      <td>128</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>7</td>\n",
              "      <td>0.959333</td>\n",
              "      <td>0.997889</td>\n",
              "      <td>0.9008</td>\n",
              "      <td>[(512, 0.3, True, 0.0), (256, 0.3, True, 0.0),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>exp07_lr_low</td>\n",
              "      <td>128</td>\n",
              "      <td>70</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>10</td>\n",
              "      <td>0.958667</td>\n",
              "      <td>0.995370</td>\n",
              "      <td>0.9021</td>\n",
              "      <td>[(512, 0.3, True, 0.0001), (256, 0.3, True, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>exp10_small</td>\n",
              "      <td>128</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>7</td>\n",
              "      <td>0.957667</td>\n",
              "      <td>0.995130</td>\n",
              "      <td>0.8938</td>\n",
              "      <td>[(256, 0.2, True, 0.0), (128, 0.2, True, 0.0),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>exp05_dropout05</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>8</td>\n",
              "      <td>0.956500</td>\n",
              "      <td>0.987315</td>\n",
              "      <td>0.8919</td>\n",
              "      <td>[(512, 0.5, True, 0.0), (256, 0.5, True, 0.0),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>exp02_wider</td>\n",
              "      <td>128</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.954833</td>\n",
              "      <td>0.996167</td>\n",
              "      <td>0.8931</td>\n",
              "      <td>[(512, 0.25, True, 0.0), (10, 0.0, False, 0.0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>exp01_baseline</td>\n",
              "      <td>128</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6</td>\n",
              "      <td>0.951833</td>\n",
              "      <td>0.993444</td>\n",
              "      <td>0.8841</td>\n",
              "      <td>[(256, 0.2, True, 0.0), (10, 0.0, False, 0.0)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38ef7ca5-2c7d-47b8-8524-e2ac9a97cf00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38ef7ca5-2c7d-47b8-8524-e2ac9a97cf00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38ef7ca5-2c7d-47b8-8524-e2ac9a97cf00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8ba893cc-aa74-4120-97e1-1eb15a7243d6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ba893cc-aa74-4120-97e1-1eb15a7243d6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8ba893cc-aa74-4120-97e1-1eb15a7243d6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5ff0890f-d864-4ff3-a11c-8beb57112257\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('experiments_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5ff0890f-d864-4ff3-a11c-8beb57112257 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('experiments_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "experiments_df",
              "summary": "{\n  \"name\": \"experiments_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"experiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"exp02_wider\",\n          \"exp08_batch64\",\n          \"exp07_lr_low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47,\n        \"min\": 64,\n        \"max\": 256,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          128,\n          64,\n          256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 40,\n        \"max\": 70,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          50,\n          40,\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00016363916944844771,\n        \"min\": 0.0005,\n        \"max\": 0.001,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.001,\n          0.0008,\n          0.0005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"patience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 6,\n        \"max\": 10,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          7,\n          6,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_val_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0034106315261850603,\n        \"min\": 0.9518333333333333,\n        \"max\": 0.9628333333333333,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9548333333333333,\n          0.962,\n          0.9586666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031538824560473026,\n        \"min\": 0.9873148148148149,\n        \"max\": 0.9988148148148148,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9961666666666666,\n          0.9961851851851852,\n          0.9953703703703703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006524662613669936,\n        \"min\": 0.8841,\n        \"max\": 0.9051,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8931,\n          0.9033,\n          0.9021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"layers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"[(512, 0.3, True, 0.0), (256, 0.3, True, 0.0), (10, 0.0, False, 0.0)]\",\n          \"[(512, 0.5, True, 0.0), (256, 0.5, True, 0.0), (10, 0.0, False, 0.0)]\",\n          \"[(512, 0.3, True, 0.0001), (256, 0.3, True, 0.0001), (10, 0.0, False, 0.0)]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "!pip -q install mlflow\n",
        "\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "import pandas as pd\n",
        "\n",
        "mlflow.set_experiment(\"ex2-kmnist-mlp\")\n",
        "\n",
        "# ---- Define experiments (at least 10) ----\n",
        "# Each experiment is a (name, TrainConfig overrides, layers list)\n",
        "EXPERIMENTS = [\n",
        "    (\"exp01_baseline\",  dict(batch_size=128, lr=1e-3, epochs=40, patience=6),\n",
        "     [LayerSpec(out_dim=256, dropout=0.2, batch_norm=True,  activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=10,  dropout=0.0, batch_norm=False, activation=nn.Identity, weight_decay=0.0)]),\n",
        "\n",
        "    (\"exp02_wider\",     dict(batch_size=128, lr=1e-3, epochs=40, patience=6),\n",
        "     [LayerSpec(out_dim=512, dropout=0.25, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=10,  dropout=0.0,  batch_norm=False, activation=nn.Identity, weight_decay=0.0)]),\n",
        "\n",
        "    (\"exp03_deeper2\",   dict(batch_size=128, lr=1e-3, epochs=50, patience=7),\n",
        "     [LayerSpec(out_dim=512, dropout=0.3, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=256, dropout=0.3, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=10,  dropout=0.0, batch_norm=False, activation=nn.Identity, weight_decay=0.0)]),\n",
        "\n",
        "    (\"exp04_deeper3\",   dict(batch_size=128, lr=8e-4, epochs=60, patience=8),\n",
        "     [LayerSpec(out_dim=512, dropout=0.35, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=256, dropout=0.35, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=128, dropout=0.25, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=10,  dropout=0.0,  batch_norm=False, activation=nn.Identity, weight_decay=0.0)]),\n",
        "\n",
        "    (\"exp05_dropout05\", dict(batch_size=128, lr=1e-3, epochs=60, patience=8),\n",
        "     [LayerSpec(out_dim=512, dropout=0.5, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=256, dropout=0.5, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=10,  dropout=0.0, batch_norm=False, activation=nn.Identity, weight_decay=0.0)]),\n",
        "\n",
        "    (\"exp06_weightdecay\", dict(batch_size=128, lr=1e-3, epochs=60, patience=8),\n",
        "     [LayerSpec(out_dim=512, dropout=0.3, batch_norm=True, activation=nn.ReLU, weight_decay=1e-4),\n",
        "      LayerSpec(out_dim=256, dropout=0.3, batch_norm=True, activation=nn.ReLU, weight_decay=1e-4),\n",
        "      LayerSpec(out_dim=10,  dropout=0.0, batch_norm=False, activation=nn.Identity, weight_decay=0.0)]),\n",
        "\n",
        "    (\"exp07_lr_low\",    dict(batch_size=128, lr=5e-4, epochs=70, patience=10),\n",
        "     [LayerSpec(out_dim=512, dropout=0.3, batch_norm=True, activation=nn.ReLU, weight_decay=1e-4),\n",
        "      LayerSpec(out_dim=256, dropout=0.3, batch_norm=True, activation=nn.ReLU, weight_decay=1e-4),\n",
        "      LayerSpec(out_dim=10,  dropout=0.0, batch_norm=False, activation=nn.Identity, weight_decay=0.0)]),\n",
        "\n",
        "    (\"exp08_batch64\",   dict(batch_size=64, lr=1e-3, epochs=60, patience=8),\n",
        "     [LayerSpec(out_dim=512, dropout=0.3, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=256, dropout=0.3, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=10,  dropout=0.0, batch_norm=False, activation=nn.Identity, weight_decay=0.0)]),\n",
        "\n",
        "    (\"exp09_batch256\",  dict(batch_size=256, lr=1e-3, epochs=50, patience=7),\n",
        "     [LayerSpec(out_dim=512, dropout=0.25, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=256, dropout=0.25, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=10,  dropout=0.0, batch_norm=False, activation=nn.Identity, weight_decay=0.0)]),\n",
        "\n",
        "    (\"exp10_small\",     dict(batch_size=128, lr=1e-3, epochs=50, patience=7),\n",
        "     [LayerSpec(out_dim=256, dropout=0.2, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=128, dropout=0.2, batch_norm=True, activation=nn.ReLU, weight_decay=0.0),\n",
        "      LayerSpec(out_dim=10,  dropout=0.0, batch_norm=False, activation=nn.Identity, weight_decay=0.0)]),\n",
        "]\n",
        "\n",
        "\n",
        "def make_loaders(batch_size, val_fraction, seed):\n",
        "    dm = DataManager(\n",
        "        dataset_class=datasets.KMNIST,\n",
        "        val_fraction=val_fraction,\n",
        "        batch_size=batch_size,\n",
        "        seed=seed\n",
        "    )\n",
        "    return dm.get_loaders()\n",
        "\n",
        "# ---- Run all experiments ----\n",
        "results_rows = []\n",
        "best = {\"name\": None, \"val_acc\": -1.0, \"trainer\": None, \"train_cfg\": None, \"model_cfg\": None, \"loaders\": None}\n",
        "\n",
        "for exp_name, cfg_overrides, layers in EXPERIMENTS:\n",
        "    # Build TrainConfig\n",
        "    train_cfg = TrainConfig(\n",
        "        batch_size=cfg_overrides.get(\"batch_size\", 128),\n",
        "        epochs=cfg_overrides.get(\"epochs\", 60),\n",
        "        lr=cfg_overrides.get(\"lr\", 1e-3),\n",
        "        patience=cfg_overrides.get(\"patience\", 8),\n",
        "        min_delta=1e-4,\n",
        "        val_fraction=0.1,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    train_loader, val_loader, test_loader = make_loaders(train_cfg.batch_size, train_cfg.val_fraction, train_cfg.seed)\n",
        "\n",
        "    model_cfg = ModelConfig(layers=layers)\n",
        "    model = MLPFromConfig(model_cfg)\n",
        "\n",
        "    trainer = Trainer(model, train_cfg)\n",
        "\n",
        "    with mlflow.start_run(run_name=exp_name):\n",
        "        # Params\n",
        "        mlflow.log_params({\n",
        "            \"batch_size\": train_cfg.batch_size,\n",
        "            \"epochs\": train_cfg.epochs,\n",
        "            \"lr\": train_cfg.lr,\n",
        "            \"patience\": train_cfg.patience,\n",
        "            \"val_fraction\": train_cfg.val_fraction,\n",
        "            \"layers\": str([(ls.out_dim, ls.dropout, ls.batch_norm, ls.weight_decay) for ls in layers])\n",
        "        })\n",
        "\n",
        "        # Train\n",
        "        trainer.fit(train_loader, val_loader)\n",
        "\n",
        "        # Best val acc during training\n",
        "        best_val_acc = float(max(trainer.history[\"val_acc\"])) if len(trainer.history[\"val_acc\"]) else 0.0\n",
        "        best_val_loss = float(min(trainer.history[\"val_loss\"])) if len(trainer.history[\"val_loss\"]) else 0.0\n",
        "\n",
        "        # Evaluate (final)\n",
        "        train_loss, train_acc = trainer.evaluate(train_loader)\n",
        "        test_loss, test_acc = trainer.evaluate(test_loader)\n",
        "\n",
        "        mlflow.log_metrics({\n",
        "            \"best_val_acc\": best_val_acc,\n",
        "            \"best_val_loss\": best_val_loss,\n",
        "            \"train_acc\": float(train_acc),\n",
        "            \"train_loss\": float(train_loss),\n",
        "            \"test_acc\": float(test_acc),\n",
        "            \"test_loss\": float(test_loss),\n",
        "        })\n",
        "\n",
        "        # Save model artifact\n",
        "        tmp_path = f\"{exp_name}_model.pt\"\n",
        "        trainer.save(tmp_path)\n",
        "        mlflow.log_artifact(tmp_path)\n",
        "\n",
        "        # Collect row\n",
        "        results_rows.append({\n",
        "            \"experiment\": exp_name,\n",
        "            \"batch_size\": train_cfg.batch_size,\n",
        "            \"epochs\": train_cfg.epochs,\n",
        "            \"lr\": train_cfg.lr,\n",
        "            \"patience\": train_cfg.patience,\n",
        "            \"best_val_acc\": best_val_acc,\n",
        "            \"train_acc\": float(train_acc),\n",
        "            \"test_acc\": float(test_acc),\n",
        "            \"layers\": str([(ls.out_dim, ls.dropout, ls.batch_norm, ls.weight_decay) for ls in layers]),\n",
        "        })\n",
        "\n",
        "        # Track best\n",
        "        if best_val_acc > best[\"val_acc\"]:\n",
        "            best.update({\n",
        "                \"name\": exp_name,\n",
        "                \"val_acc\": best_val_acc,\n",
        "                \"trainer\": trainer,\n",
        "                \"train_cfg\": train_cfg,\n",
        "                \"model_cfg\": model_cfg,\n",
        "                \"loaders\": (train_loader, val_loader, test_loader),\n",
        "            })\n",
        "\n",
        "print(f\"âœ… Finished {len(EXPERIMENTS)} experiments.\")\n",
        "print(f\"ðŸ† Best experiment: {best['name']} (best_val_acc={best['val_acc']:.4f})\")\n",
        "\n",
        "# Set the best trainer/loaders for the rest of the notebook (plots + test section)\n",
        "trainer = best[\"trainer\"]\n",
        "train_loader, val_loader, test_loader = best[\"loaders\"]\n",
        "\n",
        "#keep a DataFrame of the experiments (will be extended and exported to Excel in the next cell)\n",
        "experiments_df = pd.DataFrame(results_rows).sort_values(by=\"best_val_acc\", ascending=False)\n",
        "experiments_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e0c6f58",
      "metadata": {
        "id": "3e0c6f58"
      },
      "source": [
        "Visuazize the train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "740b2e48",
      "metadata": {
        "id": "740b2e48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ff58d120-fae0-4221-a241-e9f7c1b89091"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "history = trainer.history\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
        "plt.plot(history[\"val_loss\"],   label=\"Val Loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history[\"train_acc\"], label=\"Train Acc\")\n",
        "plt.plot(history[\"val_acc\"],   label=\"Val Acc\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5kjoDILMt2Zw",
      "metadata": {
        "id": "5kjoDILMt2Zw"
      },
      "source": [
        "Visualized the test (do change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "A-FR-NYgt6Hv",
      "metadata": {
        "id": "A-FR-NYgt6Hv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "522fa7af-85ae-4245-cfba-b844b3de745b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2705984033.py:72: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ‹ï¸ TRAIN  | Loss: 0.0079 | Acc: 0.9988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2705984033.py:72: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ† TEST   | Loss: 0.3671 | Acc: 0.9051\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9148    0.9340    0.9243      1000\n",
            "           1     0.9154    0.8870    0.9010      1000\n",
            "           2     0.8415    0.8600    0.8506      1000\n",
            "           3     0.9094    0.9530    0.9307      1000\n",
            "           4     0.9086    0.8750    0.8915      1000\n",
            "           5     0.9653    0.8890    0.9256      1000\n",
            "           6     0.8689    0.9410    0.9035      1000\n",
            "           7     0.9364    0.8830    0.9089      1000\n",
            "           8     0.8728    0.9330    0.9019      1000\n",
            "           9     0.9324    0.8960    0.9138      1000\n",
            "\n",
            "    accuracy                         0.9051     10000\n",
            "   macro avg     0.9065    0.9051    0.9052     10000\n",
            "weighted avg     0.9065    0.9051    0.9052     10000\n",
            "\n",
            "ðŸ“„ Saved Excel results to: Ameer_Espanioly_Baraa_Shaqir_Deema_Shaqir_ex2.xlsx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          experiment  batch_size  epochs      lr  patience  best_val_acc  \\\n",
              "0  exp06_weightdecay         128      60  0.0010         8      0.962833   \n",
              "1      exp08_batch64          64      60  0.0010         8      0.962000   \n",
              "2      exp04_deeper3         128      60  0.0008         8      0.961500   \n",
              "3     exp09_batch256         256      50  0.0010         7      0.959667   \n",
              "4      exp03_deeper2         128      50  0.0010         7      0.959333   \n",
              "\n",
              "   train_acc  test_acc                                             layers  \\\n",
              "0   0.998815    0.9051  [(512, 0.3, True, 0.0001), (256, 0.3, True, 0....   \n",
              "1   0.996185    0.9033  [(512, 0.3, True, 0.0), (256, 0.3, True, 0.0),...   \n",
              "2   0.993778    0.9015  [(512, 0.35, True, 0.0), (256, 0.35, True, 0.0...   \n",
              "3   0.993944    0.8970  [(512, 0.25, True, 0.0), (256, 0.25, True, 0.0...   \n",
              "4   0.997889    0.9008  [(512, 0.3, True, 0.0), (256, 0.3, True, 0.0),...   \n",
              "\n",
              "   train_precision_c0  ...  test_f1_c7  test_precision_c8  test_recall_c8  \\\n",
              "0            0.997961  ...    0.908904           0.872778           0.933   \n",
              "1                 NaN  ...         NaN                NaN             NaN   \n",
              "2                 NaN  ...         NaN                NaN             NaN   \n",
              "3                 NaN  ...         NaN                NaN             NaN   \n",
              "4                 NaN  ...         NaN                NaN             NaN   \n",
              "\n",
              "   test_f1_c8  test_precision_c9  test_recall_c9  test_f1_c9  \\\n",
              "0    0.901885           0.932362           0.896    0.913819   \n",
              "1         NaN                NaN             NaN         NaN   \n",
              "2         NaN                NaN             NaN         NaN   \n",
              "3         NaN                NaN             NaN         NaN   \n",
              "4         NaN                NaN             NaN         NaN   \n",
              "\n",
              "   test_precision_macro  test_recall_macro  test_f1_macro  \n",
              "0              0.906528             0.9051       0.905173  \n",
              "1                   NaN                NaN            NaN  \n",
              "2                   NaN                NaN            NaN  \n",
              "3                   NaN                NaN            NaN  \n",
              "4                   NaN                NaN            NaN  \n",
              "\n",
              "[5 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a8cab96-3dd3-4025-90aa-df1ef396ae30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>experiment</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>lr</th>\n",
              "      <th>patience</th>\n",
              "      <th>best_val_acc</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>layers</th>\n",
              "      <th>train_precision_c0</th>\n",
              "      <th>...</th>\n",
              "      <th>test_f1_c7</th>\n",
              "      <th>test_precision_c8</th>\n",
              "      <th>test_recall_c8</th>\n",
              "      <th>test_f1_c8</th>\n",
              "      <th>test_precision_c9</th>\n",
              "      <th>test_recall_c9</th>\n",
              "      <th>test_f1_c9</th>\n",
              "      <th>test_precision_macro</th>\n",
              "      <th>test_recall_macro</th>\n",
              "      <th>test_f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>exp06_weightdecay</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>8</td>\n",
              "      <td>0.962833</td>\n",
              "      <td>0.998815</td>\n",
              "      <td>0.9051</td>\n",
              "      <td>[(512, 0.3, True, 0.0001), (256, 0.3, True, 0....</td>\n",
              "      <td>0.997961</td>\n",
              "      <td>...</td>\n",
              "      <td>0.908904</td>\n",
              "      <td>0.872778</td>\n",
              "      <td>0.933</td>\n",
              "      <td>0.901885</td>\n",
              "      <td>0.932362</td>\n",
              "      <td>0.896</td>\n",
              "      <td>0.913819</td>\n",
              "      <td>0.906528</td>\n",
              "      <td>0.9051</td>\n",
              "      <td>0.905173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>exp08_batch64</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>8</td>\n",
              "      <td>0.962000</td>\n",
              "      <td>0.996185</td>\n",
              "      <td>0.9033</td>\n",
              "      <td>[(512, 0.3, True, 0.0), (256, 0.3, True, 0.0),...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>exp04_deeper3</td>\n",
              "      <td>128</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>8</td>\n",
              "      <td>0.961500</td>\n",
              "      <td>0.993778</td>\n",
              "      <td>0.9015</td>\n",
              "      <td>[(512, 0.35, True, 0.0), (256, 0.35, True, 0.0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>exp09_batch256</td>\n",
              "      <td>256</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>7</td>\n",
              "      <td>0.959667</td>\n",
              "      <td>0.993944</td>\n",
              "      <td>0.8970</td>\n",
              "      <td>[(512, 0.25, True, 0.0), (256, 0.25, True, 0.0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>exp03_deeper2</td>\n",
              "      <td>128</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>7</td>\n",
              "      <td>0.959333</td>\n",
              "      <td>0.997889</td>\n",
              "      <td>0.9008</td>\n",
              "      <td>[(512, 0.3, True, 0.0), (256, 0.3, True, 0.0),...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 75 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a8cab96-3dd3-4025-90aa-df1ef396ae30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a8cab96-3dd3-4025-90aa-df1ef396ae30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a8cab96-3dd3-4025-90aa-df1ef396ae30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-90d089a8-e112-4223-b706-7e75fb3e3095\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-90d089a8-e112-4223-b706-7e75fb3e3095')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-90d089a8-e112-4223-b706-7e75fb3e3095 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def compute_reports(split_name, loader):\n",
        "    loss, acc = trainer.evaluate(loader)\n",
        "    preds, targets = trainer.predict_all(loader)\n",
        "\n",
        "    # classification_report as dict\n",
        "    rep = classification_report(targets, preds, digits=4, output_dict=True, zero_division=0)\n",
        "    cm = confusion_matrix(targets, preds)\n",
        "\n",
        "    # Extract per-class metrics\n",
        "    per_class = {}\n",
        "    for cls in range(10):\n",
        "        cls_key = str(cls)\n",
        "        if cls_key in rep:\n",
        "            per_class[f\"{split_name}_precision_c{cls}\"] = rep[cls_key][\"precision\"]\n",
        "            per_class[f\"{split_name}_recall_c{cls}\"]    = rep[cls_key][\"recall\"]\n",
        "            per_class[f\"{split_name}_f1_c{cls}\"]        = rep[cls_key][\"f1-score\"]\n",
        "        else:\n",
        "            per_class[f\"{split_name}_precision_c{cls}\"] = np.nan\n",
        "            per_class[f\"{split_name}_recall_c{cls}\"]    = np.nan\n",
        "            per_class[f\"{split_name}_f1_c{cls}\"]        = np.nan\n",
        "\n",
        "    # Macro averages\n",
        "    macro = rep.get(\"macro avg\", {})\n",
        "    per_class[f\"{split_name}_precision_macro\"] = macro.get(\"precision\", np.nan)\n",
        "    per_class[f\"{split_name}_recall_macro\"]    = macro.get(\"recall\", np.nan)\n",
        "    per_class[f\"{split_name}_f1_macro\"]        = macro.get(\"f1-score\", np.nan)\n",
        "\n",
        "    return float(loss), float(acc), preds, targets, cm, rep, per_class\n",
        "\n",
        "# ---- TRAIN metrics ----\n",
        "train_loss, train_acc, train_preds, train_targets, cm_train, rep_train, train_metrics = compute_reports(\"train\", train_loader)\n",
        "print(f\"ðŸ‹ï¸ TRAIN  | Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
        "\n",
        "# ---- TEST metrics ----\n",
        "test_loss, test_acc, test_preds, test_targets, cm_test, rep_test, test_metrics = compute_reports(\"test\", test_loader)\n",
        "print(f\"ðŸ† TEST   | Loss: {test_loss:.4f} | Acc: {test_acc:.4f}\")\n",
        "\n",
        "# ---- Visualize confusion matrix (TEST) ----\n",
        "plt.figure()\n",
        "plt.imshow(cm_test)\n",
        "plt.title(\"Confusion Matrix (Test)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "print(\"Classification report (Test):\")\n",
        "print(classification_report(test_targets, test_preds, digits=4, zero_division=0))\n",
        "\n",
        "\n",
        "best_row = experiments_df.iloc[0].to_dict()\n",
        "\n",
        "# Add macro + per-class (best model)\n",
        "best_row.update(train_metrics)\n",
        "best_row.update(test_metrics)\n",
        "\n",
        "final_df = pd.DataFrame([best_row] + [r for _, r in experiments_df.iloc[1:].iterrows()])\n",
        "\n",
        "# Export\n",
        "excel_path = \"Ameer_Espanioly_Baraa_Shaqir_Deema_Shaqir_ex2.xlsx\"\n",
        "final_df.to_excel(excel_path, index=False)\n",
        "print(f\"ðŸ“„ Saved Excel results to: {excel_path}\")\n",
        "\n",
        "# Log into MLflow as an artifact too\n",
        "try:\n",
        "    import mlflow\n",
        "    mlflow.log_artifact(excel_path)\n",
        "except Exception as e:\n",
        "    print(\"MLflow artifact logging skipped:\", e)\n",
        "\n",
        "final_df.head(5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}